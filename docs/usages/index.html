<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="../img/favicon.ico">
    <title>Usages &mdash; Kindle</title>
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/tonsky/FiraCode@1.206/distr/fira_code.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/all.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/v4-shims.css">
    <link rel="stylesheet" href="../css/theme.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    <script src="//code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>
        hljs.initHighlightingOnLoad();
    </script> 
</head>

<body ontouchstart="">
    <div id="container">
        <aside>
            <div class="home">
                <div class="title">
                    <button class="hamburger"></button>
                    <a href=".." class="site-name"> Kindle</a>
                </div>
                <div class="search">
                    <div role="search">
    <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
        <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
    </form>
</div>
                </div>
            </div>
            <nav class="nav">
                <ul class="root">
                    <li class="toctree-l1"><a class="nav-item" href="..">Home</a></li>
                    <li class="toctree-l1"><a class="nav-item" href="../functionality/">Functionality</a></li>
                    <li class="toctree-l1"><a class="nav-item" href="../tutorial/">Tutorial</a></li>
                    <li class="toctree-l1 current"><a class="nav-item current" href="./">Usages</a>
<ul class="subnav">
<li class="toctree-l2"><a class="nav-item toc" href="#automl-with-optuna">AutoML with Optuna</a></li>
</ul></li>
                    <li class="toctree-l1"><a class="nav-item" href="../modules/">Modules</a></li>
                </ul>
            </nav>
            <div class="repo">
    <div class="link">
        <a href="https://github.com/JeiKeiLim/kindle/" class="fa fa-github"> GitHub</a>
    </div>
    <div class="previous"><a href="../tutorial/">&laquo; Previous</a></div>
    <div class="next"><a href="../modules/">Next &raquo;</a></div>
</div>
        </aside>
        <div id="spacer"><button class="arrow"></button></div>
        <main>
            <div class="home-top">
                <button class="hamburger"></button>
                <a href=".." class="site-name"> Kindle</a>
            </div>
            <div id="main">
                <nav class="breadcrumbs">
<ul>
    
</ul>
</nav>
                <div id="content"><h1 id="usages">Usages</h1>
<h2 id="automl-with-optuna">AutoML with Optuna</h2>
<p><a href="https://github.com/jeikeilim/kindle">Kindle</a> offers the easiest way to build your own deep learning architecture. Beyond building a model, AutoML became easier with <a href="https://github.com/jeikeilim/kindle">Kindle</a> and <a href="https://optuna.org">Optuna</a> or other optimization frameworks.</p>
<h3 id="example-code">Example code</h3>
<pre class="highlight"><code class="language-python">import torch
from torch import nn, optim
from torchvision import datasets, transforms
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader

from kindle import Model, TorchTrainer
import optuna


if __name__ == "__main__":
    device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
    preprocess = transforms.Compose(
        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    )
    train_dataset = datasets.CIFAR10(
        "./data/cifar10", train=True, download=True, transform=preprocess
    )
    test_dataset = datasets.CIFAR10(
        "./data/cifar10", train=False, download=True, transform=preprocess
    )
    subset_sampler = SubsetRandomSampler(np.arange(0, len(train_dataset), 2))

    def objective(trial: optuna.Trial):
        model_cfg = {"input_size": [32, 32],
                     "input_channel": 3,
                     "depth_multiple": 1.0,
                     "width_multiple": 1.0}
        conv_type = trial.suggest_categorical("conv_type", ["Conv", "DWConv"])
        kernel_size = trial.suggest_int("kernel_size", 3, 7, step=2)
        n_channel_01 = trial.suggest_int("n_channel_01", 8, 64, step=8)
        n_channel_02 = trial.suggest_int("n_channel_02", 8, 128, step=8)

        linear_activation = trial.suggest_categorical("linear_activation", ["ReLU", "SiLU"])
        n_channel_03 = trial.suggest_int("n_channel_03", 64, 256, step=8)
        n_channel_04 = trial.suggest_int("n_channel_04", 32, 128, step=8)
        n_repeat = trial.suggest_int("n_repeat", 1, 3)

        backbone = [
            [-1, n_repeat, conv_type, [n_channel_01, kernel_size, 1]],
            [-1, 1, "MaxPool", [2]],
            [-1, n_repeat, conv_type, [int(n_channel_02), kernel_size, 1]],
            [-1, 1, "MaxPool", [2]],
            [-1, 1, "Flatten", []],
            [-1, 1, "Linear", [n_channel_03, linear_activation]],
            [-1, 1, "Linear", [n_channel_04, linear_activation]],
            [-1, 1, "Linear", [10]],
        ]
        model_cfg.update({"backbone": backbone})

        model = Model(model_cfg, verbose=True)
        batch_size = trial.suggest_int("batch_size", 8, 256)
        epochs = trial.suggest_int("epochs", 5, 20)

        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, sampler=subset_sampler
        )
        test_loader = DataLoader(test_dataset, batch_size=batch_size)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters())

        trainer = TorchTrainer(model, criterion, optimizer, device=device)
        trainer.train(train_loader, n_epoch=epochs, test_dataloader=test_loader)
        test_loss, test_accuracy = trainer.test(test_loader)

        return test_loss

    study = optuna.create_study(study_name="Sample AutoML", direction="minimize")
    study.optimize(objective)</code></pre></div>
                <footer>
    <div class="footer-buttons">
        <div class="previous"><a href="../tutorial/" title="Tutorial"><span>Previous</span></a></div>
        <div class="next"><a href="../modules/" title="Modules"><span>Next</span></a></div>
    </div>
    <div class="footer-note">
        <p>
            Built with <a href="http://www.mkdocs.org">MkDocs</a> using
            <a href="https://github.com/daizutabi/mkdocs-ivory">Ivory theme</a>.
        </p>
    </div>
</footer>
            </div>
        </main>
    </div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
    <script src="../search/main.js"></script>
</body>

</html>