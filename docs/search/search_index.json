{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kindle - Making a PyTorch model easier than ever! Kindle is an easy model build package for PyTorch . Building a deep learning model became so simple that almost all model can be made by copy and paste from other existing model codes. So why code? when we can simply build a model with yaml markup file. Kindle builds a model with yaml file which its method is inspired from YOLOv5 . Installation PyTorch is required prior to install. Please visit PyTorch installation guide to install. You can install kindle by pip. $ pip install kindle","title":"Home"},{"location":"#kindle-making-a-pytorch-model-easier-than-ever","text":"Kindle is an easy model build package for PyTorch . Building a deep learning model became so simple that almost all model can be made by copy and paste from other existing model codes. So why code? when we can simply build a model with yaml markup file. Kindle builds a model with yaml file which its method is inspired from YOLOv5 .","title":"Kindle - Making a PyTorch model easier than ever!"},{"location":"#installation","text":"PyTorch is required prior to install. Please visit PyTorch installation guide to install. You can install kindle by pip. $ pip install kindle","title":"Installation"},{"location":"functionality/","text":"Functionalities 1. Model Profiling Basic profiling Kindle model provides profiling option. Please refer to API reference page for the detailed information. from kindle import Model model = Model ( \"model.yaml\" ) profiler = model . profile ( n_run = 100 , batch_size = 32 , input_size = ( 224 , 224 ), verbose = True ) Above code will print the profiling result as following. Profiling result by 100 times running. Sorted by running order. ------------------------------------------------------------------------------------------------------ idx | Name | Time ( Mean ) | Time ( Std ) | Time ( Total ) | Rank | Ratio | Params | ------------------------------------------------------------------------------------------------------ 0 | Conv | 1 .40 ms | 566 .86 \u03bcs | 139 .69 ms | 1 | 36 .08% | 616 | 1 | MaxPool | 410 .78 \u03bcs | 136 .45 \u03bcs | 41 .08 ms | 3 | 10 .61% | 0 | 2 | nn.Conv2d | 980 .33 \u03bcs | 459 .86 \u03bcs | 98 .03 ms | 2 | 25 .32% | 3 ,200 | 3 | nn.BatchNorm2d | 277 .48 \u03bcs | 141 .98 \u03bcs | 27 .75 ms | 5 | 7 .17% | 32 | 4 | nn.ReLU | 109 .23 \u03bcs | 43 .48 \u03bcs | 10 .92 ms | 7 | 2 .82% | 0 | 5 | MaxPool | 242 .73 \u03bcs | 80 .28 \u03bcs | 24 .27 ms | 6 | 6 .27% | 0 | 6 | Flatten | 18 .18 \u03bcs | 16 .98 \u03bcs | 1 .82 ms | 10 | 0 .47% | 0 | 7 | Linear | 294 .72 \u03bcs | 192 .97 \u03bcs | 29 .47 ms | 4 | 7 .61% | 123 ,000 | 8 | Linear | 94 .48 \u03bcs | 44 .85 \u03bcs | 9 .45 ms | 8 | 2 .44% | 10 ,164 | 9 | Linear | 46 .44 \u03bcs | 26 .23 \u03bcs | 4 .64 ms | 9 | 1 .20% | 850 | ------------------------------------------------------------------------------------------------------ Running time - Total : 387 .13 ms - Mean : 3 .87 ms - STD : 1 .45 ms Profiling by time consumption order Profiling result can be sorted by running times. profiler . print_result ( sort_by_rank = True ) Profiling result by 100 times running. Sorted by time consumption. ------------------------------------------------------------------------------------------------------ idx | Name | Time ( Mean ) | Time ( Std ) | Time ( Total ) | Rank | Ratio | Params | ------------------------------------------------------------------------------------------------------ 0 | Conv | 1 .40 ms | 566 .86 \u03bcs | 139 .69 ms | 1 | 36 .08% | 616 | 2 | nn.Conv2d | 980 .33 \u03bcs | 459 .86 \u03bcs | 98 .03 ms | 2 | 25 .32% | 3 ,200 | 1 | MaxPool | 410 .78 \u03bcs | 136 .45 \u03bcs | 41 .08 ms | 3 | 10 .61% | 0 | 7 | Linear | 294 .72 \u03bcs | 192 .97 \u03bcs | 29 .47 ms | 4 | 7 .61% | 123 ,000 | 3 | nn.BatchNorm2d | 277 .48 \u03bcs | 141 .98 \u03bcs | 27 .75 ms | 5 | 7 .17% | 32 | 5 | MaxPool | 242 .73 \u03bcs | 80 .28 \u03bcs | 24 .27 ms | 6 | 6 .27% | 0 | 4 | nn.ReLU | 109 .23 \u03bcs | 43 .48 \u03bcs | 10 .92 ms | 7 | 2 .82% | 0 | 8 | Linear | 94 .48 \u03bcs | 44 .85 \u03bcs | 9 .45 ms | 8 | 2 .44% | 10 ,164 | 9 | Linear | 46 .44 \u03bcs | 26 .23 \u03bcs | 4 .64 ms | 9 | 1 .20% | 850 | 6 | Flatten | 18 .18 \u03bcs | 16 .98 \u03bcs | 1 .82 ms | 10 | 0 .47% | 0 | ------------------------------------------------------------------------------------------------------ Running time - Total : 387 .13 ms - Mean : 3 .87 ms - STD : 1 .45 ms 2. Get MACs MACs is Multiply-accumulate operation which represents computational expense. Approximately 1 MACs = 0.5 * FLOPs Kindle is using ptflops for computing MACs. mac = profiler . get_macs ( verbose = True ) print ( f \" { mac : ,0d } MACs\" ) Model ( 0 .138 M, 100 .000% Params, 0 .002 GMac, 100 .000% MACs, ( model ) : Sequential ( 0 .138 M, 100 .000% Params, 0 .002 GMac, 100 .000% MACs, ( 0 ) : Conv ( 0 .001 M, 0 .447% Params, 0 .001 GMac, 39 .517% MACs, ( conv ) : Conv2d ( 0 .001 M, 0 .435% Params, 0 .001 GMac, 37 .997% MACs, 3 , 8 , kernel_size =( 5 , 5 ) , stride =( 1 , 1 ) , padding =[ 2 ] , bias = False ) ( batch_norm ) : BatchNorm2d ( 0 .0 M, 0 .012% Params, 0 .0 GMac, 1 .013% MACs, 8 , eps = 1e-05, momentum = 0 .1, affine = True, track_running_stats = True ) ( activation ) : LeakyReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .507% MACs, negative_slope = 0 .01 ) ) ( 1 ) : MaxPool2d ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .507% MACs, kernel_size = 2 , stride = 2 , padding = 0 , dilation = 1 , ceil_mode = False ) ( 2 ) : Conv2d ( 0 .003 M, 2 .321% Params, 0 .001 GMac, 50 .663% MACs, 8 , 16 , kernel_size =( 5 , 5 ) , stride =( 1 , 1 ) , padding =( 2 , 2 ) , bias = False ) ( 3 ) : BatchNorm2d ( 0 .0 M, 0 .023% Params, 0 .0 GMac, 0 .507% MACs, 16 , eps = 1e-05, momentum = 0 .1, affine = True, track_running_stats = True ) ( 4 ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .253% MACs, inplace = True ) ( 5 ) : MaxPool2d ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .253% MACs, kernel_size = 2 , stride = 2 , padding = 0 , dilation = 1 , ceil_mode = False ) ( 6 ) : Flatten ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .000% MACs, start_dim = 1 , end_dim = -1 ) ( 7 ) : Linear ( 0 .123 M, 89 .220% Params, 0 .0 GMac, 7 .614% MACs, ( linear ) : Linear ( 0 .123 M, 89 .220% Params, 0 .0 GMac, 7 .607% MACs, in_features = 1024 , out_features = 120 , bias = True ) ( activation ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .007% MACs, ) ) ( 8 ) : Linear ( 0 .01 M, 7 .373% Params, 0 .0 GMac, 0 .634% MACs, ( linear ) : Linear ( 0 .01 M, 7 .373% Params, 0 .0 GMac, 0 .629% MACs, in_features = 120 , out_features = 84 , bias = True ) ( activation ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .005% MACs, ) ) ( 9 ) : Linear ( 0 .001 M, 0 .617% Params, 0 .0 GMac, 0 .053% MACs, ( linear ) : Linear ( 0 .001 M, 0 .617% Params, 0 .0 GMac, 0 .053% MACs, in_features = 84 , out_features = 10 , bias = True ) ( activation ) : Identity ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .000% MACs, ) ) ) ) 1 ,616,970 MACs 3. Test Time Augmentation Kindle model supports TTA with simple usage. Reference document: https://limjk.ai/kindle/api/kindle.model/#kindle.model.Model.forward TTA with explicit functions import torch import torch.nn.functional as F import numpy as np from kindle import Model @torch . no_grad () def aug_flip_lr ( x : torch . Tensor ) -> torch . Tensor : return torch . flip ( x , dims = [ - 1 ]) @torch . no_grad () def aug_flip_ud ( x : torch . Tensor ) -> torch . Tensor : return torch . flip ( x , dims = [ - 2 ]) @torch . no_grad () def aug_random_scale ( x : torch . Tensor ) -> torch . Tensor : ratio = np . random . uniform ( 0.8 , 1.2 ) xr = F . interpolate ( x , scale_factor = ratio ) if xr . shape [ 2 :] != x . shape [ 2 :]: h1 , w1 = x . shape [ 2 :] h2 , w2 = xr . shape [ 2 :] xr = F . pad ( xr , [ 0 , w1 - w2 , 0 , h1 - h2 ], value = 0 ) return xr aug_funcs = [ aug_flip_lr , aug_flip_ud , aug_random_scale ] model = Model ( \"model.yaml\" ) model_in = torch . rand ( 1 , 3 , 32 , 32 ) model_out = model ( model_in , augment_func = aug_funcs ) model_out in the above code contains 4 elements which are outputs of the model with each 3 augmentations and original model_in . TTA with repeating one augmentation function If a single augmentation function is given to augment_func , TTA will consider as random augmentation and run the network repeating n_augment times. model_out = model ( model_in , augment_func = aug_random_scale , n_augment = 5 ) model_out in the above code contains 6 elements which are outputs of the model with 5 aug_random_scale applied and original model_in .","title":"Functionality"},{"location":"functionality/#functionalities","text":"","title":"Functionalities"},{"location":"functionality/#1-model-profiling","text":"","title":"1. Model Profiling"},{"location":"functionality/#basic-profiling","text":"Kindle model provides profiling option. Please refer to API reference page for the detailed information. from kindle import Model model = Model ( \"model.yaml\" ) profiler = model . profile ( n_run = 100 , batch_size = 32 , input_size = ( 224 , 224 ), verbose = True ) Above code will print the profiling result as following. Profiling result by 100 times running. Sorted by running order. ------------------------------------------------------------------------------------------------------ idx | Name | Time ( Mean ) | Time ( Std ) | Time ( Total ) | Rank | Ratio | Params | ------------------------------------------------------------------------------------------------------ 0 | Conv | 1 .40 ms | 566 .86 \u03bcs | 139 .69 ms | 1 | 36 .08% | 616 | 1 | MaxPool | 410 .78 \u03bcs | 136 .45 \u03bcs | 41 .08 ms | 3 | 10 .61% | 0 | 2 | nn.Conv2d | 980 .33 \u03bcs | 459 .86 \u03bcs | 98 .03 ms | 2 | 25 .32% | 3 ,200 | 3 | nn.BatchNorm2d | 277 .48 \u03bcs | 141 .98 \u03bcs | 27 .75 ms | 5 | 7 .17% | 32 | 4 | nn.ReLU | 109 .23 \u03bcs | 43 .48 \u03bcs | 10 .92 ms | 7 | 2 .82% | 0 | 5 | MaxPool | 242 .73 \u03bcs | 80 .28 \u03bcs | 24 .27 ms | 6 | 6 .27% | 0 | 6 | Flatten | 18 .18 \u03bcs | 16 .98 \u03bcs | 1 .82 ms | 10 | 0 .47% | 0 | 7 | Linear | 294 .72 \u03bcs | 192 .97 \u03bcs | 29 .47 ms | 4 | 7 .61% | 123 ,000 | 8 | Linear | 94 .48 \u03bcs | 44 .85 \u03bcs | 9 .45 ms | 8 | 2 .44% | 10 ,164 | 9 | Linear | 46 .44 \u03bcs | 26 .23 \u03bcs | 4 .64 ms | 9 | 1 .20% | 850 | ------------------------------------------------------------------------------------------------------ Running time - Total : 387 .13 ms - Mean : 3 .87 ms - STD : 1 .45 ms","title":"Basic profiling"},{"location":"functionality/#profiling-by-time-consumption-order","text":"Profiling result can be sorted by running times. profiler . print_result ( sort_by_rank = True ) Profiling result by 100 times running. Sorted by time consumption. ------------------------------------------------------------------------------------------------------ idx | Name | Time ( Mean ) | Time ( Std ) | Time ( Total ) | Rank | Ratio | Params | ------------------------------------------------------------------------------------------------------ 0 | Conv | 1 .40 ms | 566 .86 \u03bcs | 139 .69 ms | 1 | 36 .08% | 616 | 2 | nn.Conv2d | 980 .33 \u03bcs | 459 .86 \u03bcs | 98 .03 ms | 2 | 25 .32% | 3 ,200 | 1 | MaxPool | 410 .78 \u03bcs | 136 .45 \u03bcs | 41 .08 ms | 3 | 10 .61% | 0 | 7 | Linear | 294 .72 \u03bcs | 192 .97 \u03bcs | 29 .47 ms | 4 | 7 .61% | 123 ,000 | 3 | nn.BatchNorm2d | 277 .48 \u03bcs | 141 .98 \u03bcs | 27 .75 ms | 5 | 7 .17% | 32 | 5 | MaxPool | 242 .73 \u03bcs | 80 .28 \u03bcs | 24 .27 ms | 6 | 6 .27% | 0 | 4 | nn.ReLU | 109 .23 \u03bcs | 43 .48 \u03bcs | 10 .92 ms | 7 | 2 .82% | 0 | 8 | Linear | 94 .48 \u03bcs | 44 .85 \u03bcs | 9 .45 ms | 8 | 2 .44% | 10 ,164 | 9 | Linear | 46 .44 \u03bcs | 26 .23 \u03bcs | 4 .64 ms | 9 | 1 .20% | 850 | 6 | Flatten | 18 .18 \u03bcs | 16 .98 \u03bcs | 1 .82 ms | 10 | 0 .47% | 0 | ------------------------------------------------------------------------------------------------------ Running time - Total : 387 .13 ms - Mean : 3 .87 ms - STD : 1 .45 ms","title":"Profiling by time consumption order"},{"location":"functionality/#2-get-macs","text":"MACs is Multiply-accumulate operation which represents computational expense. Approximately 1 MACs = 0.5 * FLOPs Kindle is using ptflops for computing MACs. mac = profiler . get_macs ( verbose = True ) print ( f \" { mac : ,0d } MACs\" ) Model ( 0 .138 M, 100 .000% Params, 0 .002 GMac, 100 .000% MACs, ( model ) : Sequential ( 0 .138 M, 100 .000% Params, 0 .002 GMac, 100 .000% MACs, ( 0 ) : Conv ( 0 .001 M, 0 .447% Params, 0 .001 GMac, 39 .517% MACs, ( conv ) : Conv2d ( 0 .001 M, 0 .435% Params, 0 .001 GMac, 37 .997% MACs, 3 , 8 , kernel_size =( 5 , 5 ) , stride =( 1 , 1 ) , padding =[ 2 ] , bias = False ) ( batch_norm ) : BatchNorm2d ( 0 .0 M, 0 .012% Params, 0 .0 GMac, 1 .013% MACs, 8 , eps = 1e-05, momentum = 0 .1, affine = True, track_running_stats = True ) ( activation ) : LeakyReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .507% MACs, negative_slope = 0 .01 ) ) ( 1 ) : MaxPool2d ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .507% MACs, kernel_size = 2 , stride = 2 , padding = 0 , dilation = 1 , ceil_mode = False ) ( 2 ) : Conv2d ( 0 .003 M, 2 .321% Params, 0 .001 GMac, 50 .663% MACs, 8 , 16 , kernel_size =( 5 , 5 ) , stride =( 1 , 1 ) , padding =( 2 , 2 ) , bias = False ) ( 3 ) : BatchNorm2d ( 0 .0 M, 0 .023% Params, 0 .0 GMac, 0 .507% MACs, 16 , eps = 1e-05, momentum = 0 .1, affine = True, track_running_stats = True ) ( 4 ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .253% MACs, inplace = True ) ( 5 ) : MaxPool2d ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .253% MACs, kernel_size = 2 , stride = 2 , padding = 0 , dilation = 1 , ceil_mode = False ) ( 6 ) : Flatten ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .000% MACs, start_dim = 1 , end_dim = -1 ) ( 7 ) : Linear ( 0 .123 M, 89 .220% Params, 0 .0 GMac, 7 .614% MACs, ( linear ) : Linear ( 0 .123 M, 89 .220% Params, 0 .0 GMac, 7 .607% MACs, in_features = 1024 , out_features = 120 , bias = True ) ( activation ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .007% MACs, ) ) ( 8 ) : Linear ( 0 .01 M, 7 .373% Params, 0 .0 GMac, 0 .634% MACs, ( linear ) : Linear ( 0 .01 M, 7 .373% Params, 0 .0 GMac, 0 .629% MACs, in_features = 120 , out_features = 84 , bias = True ) ( activation ) : ReLU ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .005% MACs, ) ) ( 9 ) : Linear ( 0 .001 M, 0 .617% Params, 0 .0 GMac, 0 .053% MACs, ( linear ) : Linear ( 0 .001 M, 0 .617% Params, 0 .0 GMac, 0 .053% MACs, in_features = 84 , out_features = 10 , bias = True ) ( activation ) : Identity ( 0 .0 M, 0 .000% Params, 0 .0 GMac, 0 .000% MACs, ) ) ) ) 1 ,616,970 MACs","title":"2. Get MACs"},{"location":"functionality/#3-test-time-augmentation","text":"Kindle model supports TTA with simple usage. Reference document: https://limjk.ai/kindle/api/kindle.model/#kindle.model.Model.forward","title":"3. Test Time Augmentation"},{"location":"functionality/#tta-with-explicit-functions","text":"import torch import torch.nn.functional as F import numpy as np from kindle import Model @torch . no_grad () def aug_flip_lr ( x : torch . Tensor ) -> torch . Tensor : return torch . flip ( x , dims = [ - 1 ]) @torch . no_grad () def aug_flip_ud ( x : torch . Tensor ) -> torch . Tensor : return torch . flip ( x , dims = [ - 2 ]) @torch . no_grad () def aug_random_scale ( x : torch . Tensor ) -> torch . Tensor : ratio = np . random . uniform ( 0.8 , 1.2 ) xr = F . interpolate ( x , scale_factor = ratio ) if xr . shape [ 2 :] != x . shape [ 2 :]: h1 , w1 = x . shape [ 2 :] h2 , w2 = xr . shape [ 2 :] xr = F . pad ( xr , [ 0 , w1 - w2 , 0 , h1 - h2 ], value = 0 ) return xr aug_funcs = [ aug_flip_lr , aug_flip_ud , aug_random_scale ] model = Model ( \"model.yaml\" ) model_in = torch . rand ( 1 , 3 , 32 , 32 ) model_out = model ( model_in , augment_func = aug_funcs ) model_out in the above code contains 4 elements which are outputs of the model with each 3 augmentations and original model_in .","title":"TTA with explicit functions"},{"location":"functionality/#tta-with-repeating-one-augmentation-function","text":"If a single augmentation function is given to augment_func , TTA will consider as random augmentation and run the network repeating n_augment times. model_out = model ( model_in , augment_func = aug_random_scale , n_augment = 5 ) model_out in the above code contains 6 elements which are outputs of the model with 5 aug_random_scale applied and original model_in .","title":"TTA with repeating one augmentation function"},{"location":"modules/","text":"Kindle Modules Supported Modules Summary Module Components Arguments Conv Conv -> BatchNorm -> Activation [out_channels, kernel_size, stride, padding, groups, activation] DWConv DWConv -> BatchNorm -> Activation [out_channels, kernel_size, stride, padding, activation] Focus Reshape x -> Conv -> Concat [out_channels, kernel_size, stride, padding, activation] Bottleneck Expansion ConvBNAct -> ConvBNAct [out_channels, shortcut, groups, expansion, activation] BottleneckCSP CSP Bottleneck [out_channels, shortcut, groups, expansion, activation] C3 CSP Bottleneck with 3 Conv [out_channels, shortcut, groups, expansion, activation] AvgPool Average pooling [kernel_size, stride, padding] MaxPool Max pooling [kernel_size, stride, padding] GlobalAvgPool Global Average Pooling [] SPP Spatial Pyramid Pooling [out_channels, [kernel_size1, kernel_size2, ...], activation] Flatten Flatten [] Concat Concatenation [dimension] Linear Linear [out_channels, activation] Add Add [] UpSample UpSample [] Identity Identity [] YamlModule Custom module from yaml file ['yaml/file/path', arg0, arg1, ...] nn.{module_name} PyTorch torch.nn.* module Please refer to https://pytorch.org/docs/stable/nn.html Pretrained timm.create_model [model_name, use_feature_maps, features_only, pretrained] PreTrainedFeatureMap Bypass feature layer map from Pretrained [feature_idx] YOLOHead YOLOv5 head module [n_classes, anchors] Note nn.{module_name} is currently experimental. This might change in the future release. Use with caution. Conv Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input groups int 1 Group convolution size. If 1, no group convolution activation str or None \"ReLU\" If None, no activation(Identity) is applied. Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html for further detail. DWConv Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input activation str or None \"ReLU\" If None, no activation(Identity) is applied. DWConv is identical to Conv but with force grouped convolution. Focus Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input groups int 1 Group convolution size. If 1, no group convolution activation str or None \"ReLU\" If None, no activation(Identity) is applied. Bottleneck Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied. BottleneckCSP Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied. C3 Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied. AvgPool Argument name Type Default value Description kernel_size int stride int or None None padding int 0 ceil_mode bool False count_include_pad bool True divisor_override bool or None None Please refer to https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html for further detail. MaxPool Argument name Type Default value Description kernel_size int stride int or None None padding int 0 dilation int 1 return_indices bool False ceil_mode bool False Please refer to https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html for further detail. SPP Argument name Type Default value Description out_channels int Conv channels kernel_sizes List[int] List of (n, n) kernel size activation str or None \"ReLU\" If None, no activation(Identity) is applied. Flatten Argument name Type Default value Description start_dim int 1 end_dim int -1 Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html for further detail. Concat Argument name Type Default value Description dimension int 1 Linear Argument name Type Default value Description out_channels int activation str or None None UpSample Argument name Type Default value Description size int or None None scale_factor int or None 2 mode str nearest align_corners bool or None None Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html for further detail. YamlModule Argument name Type Default value Description verbose bool False yaml file path and argument configured in yaml module can not be passed through keyword argument. Pretrained Argument name Type Default value Description model_name str Please refer to https://rwightman.github.io/pytorch-image-models/results for supported models. ues_feature_maps bool False If True, return value of the module will be list of each feature maps. List[torch.Tensor] (features_only must be True in this case). Otherwise, returns last feature map. features_only bool True If True, skip classification layer and use feature layers only. torch.Tensor pretrained bool True use pretrained weight In case you are just lazy as I am, here is list of pretrained model names. ( timm==0.4.5 ) 'adv_inception_v3', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b2a', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b3a', 'efficientnet_em', 'efficientnet_es', 'efficientnet_lite0', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'gernet_l', 'gernet_m', 'gernet_s', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_rw', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0c', 'pnasnet5large', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet34', 'resnet34d', 'resnet50', 'resnet50d', 'resnet101d', 'resnet152d', 'resnet200d', 'resnetblur50', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_100', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext50_32x4d', 'skresnet18', 'skresnet34', 'skresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tresnet_l', 'tresnet_l_448', 'tresnet_m', 'tresnet_m_448', 'tresnet_xl', 'tresnet_xl_448', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_base_patch16_224', 'vit_base_patch16_224_in21k', 'vit_base_patch16_384', 'vit_base_patch32_224_in21k', 'vit_base_patch32_384', 'vit_base_resnet50_224_in21k', 'vit_base_resnet50_384', 'vit_deit_base_distilled_patch16_224', 'vit_deit_base_distilled_patch16_384', 'vit_deit_base_patch16_224', 'vit_deit_base_patch16_384', 'vit_deit_small_distilled_patch16_224', 'vit_deit_small_patch16_224', 'vit_deit_tiny_distilled_patch16_224', 'vit_deit_tiny_patch16_224', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_small_patch16_224', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception65', 'xception71' PretrainedFeatureMap Argument name Type Default value Description feature_idx int -1 Index of the feature maps YOLOHead Argument name Type Default value Description n_classes int Number of classes to detect anchors List[List[float]] Anchor lists. Each list represents each layer's anchor and each components in the list represents anchor size of [w1, h1, w2, h2, ...] Note [[-3, -2, -1], 1, YOLOHead, [80, [[100, 200, 200, 100, 200, 200], [50, 100, 100, 50, 100, 100], [10, 20, 20, 10, 20, 20]]]] This represents that YOLOHead takes inputs from previous 3 layers, detects 80 classes with 3 layers of 3 anchors.","title":"Modules"},{"location":"modules/#kindle-modules","text":"","title":"Kindle Modules"},{"location":"modules/#supported-modules-summary","text":"Module Components Arguments Conv Conv -> BatchNorm -> Activation [out_channels, kernel_size, stride, padding, groups, activation] DWConv DWConv -> BatchNorm -> Activation [out_channels, kernel_size, stride, padding, activation] Focus Reshape x -> Conv -> Concat [out_channels, kernel_size, stride, padding, activation] Bottleneck Expansion ConvBNAct -> ConvBNAct [out_channels, shortcut, groups, expansion, activation] BottleneckCSP CSP Bottleneck [out_channels, shortcut, groups, expansion, activation] C3 CSP Bottleneck with 3 Conv [out_channels, shortcut, groups, expansion, activation] AvgPool Average pooling [kernel_size, stride, padding] MaxPool Max pooling [kernel_size, stride, padding] GlobalAvgPool Global Average Pooling [] SPP Spatial Pyramid Pooling [out_channels, [kernel_size1, kernel_size2, ...], activation] Flatten Flatten [] Concat Concatenation [dimension] Linear Linear [out_channels, activation] Add Add [] UpSample UpSample [] Identity Identity [] YamlModule Custom module from yaml file ['yaml/file/path', arg0, arg1, ...] nn.{module_name} PyTorch torch.nn.* module Please refer to https://pytorch.org/docs/stable/nn.html Pretrained timm.create_model [model_name, use_feature_maps, features_only, pretrained] PreTrainedFeatureMap Bypass feature layer map from Pretrained [feature_idx] YOLOHead YOLOv5 head module [n_classes, anchors] Note nn.{module_name} is currently experimental. This might change in the future release. Use with caution.","title":"Supported Modules Summary"},{"location":"modules/#conv","text":"Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input groups int 1 Group convolution size. If 1, no group convolution activation str or None \"ReLU\" If None, no activation(Identity) is applied. Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html for further detail.","title":"Conv"},{"location":"modules/#dwconv","text":"Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input activation str or None \"ReLU\" If None, no activation(Identity) is applied. DWConv is identical to Conv but with force grouped convolution.","title":"DWConv"},{"location":"modules/#focus","text":"Argument name Type Default value Description out_channels int Conv channels kernel_size int (n, n) kernel size stride int 1 Conv stride padding int None Conv padding. If None, auto-padding will be applied which generates same width and height of the input groups int 1 Group convolution size. If 1, no group convolution activation str or None \"ReLU\" If None, no activation(Identity) is applied.","title":"Focus"},{"location":"modules/#bottleneck","text":"Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied.","title":"Bottleneck"},{"location":"modules/#bottleneckcsp","text":"Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied.","title":"BottleneckCSP"},{"location":"modules/#c3","text":"Argument name Type Default value Description out_channels int Conv channels shortcut bool True Use shortcut. Only applied when in_channels and out_channels are same. groups int 1 Group convolution size. If 1, no group convolution expansion int 0.5 Expansion(squeeze) ratio. activation str or None \"ReLU\" If None, no activation(Identity) is applied.","title":"C3"},{"location":"modules/#avgpool","text":"Argument name Type Default value Description kernel_size int stride int or None None padding int 0 ceil_mode bool False count_include_pad bool True divisor_override bool or None None Please refer to https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html for further detail.","title":"AvgPool"},{"location":"modules/#maxpool","text":"Argument name Type Default value Description kernel_size int stride int or None None padding int 0 dilation int 1 return_indices bool False ceil_mode bool False Please refer to https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html for further detail.","title":"MaxPool"},{"location":"modules/#spp","text":"Argument name Type Default value Description out_channels int Conv channels kernel_sizes List[int] List of (n, n) kernel size activation str or None \"ReLU\" If None, no activation(Identity) is applied.","title":"SPP"},{"location":"modules/#flatten","text":"Argument name Type Default value Description start_dim int 1 end_dim int -1 Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html for further detail.","title":"Flatten"},{"location":"modules/#concat","text":"Argument name Type Default value Description dimension int 1","title":"Concat"},{"location":"modules/#linear","text":"Argument name Type Default value Description out_channels int activation str or None None","title":"Linear"},{"location":"modules/#upsample","text":"Argument name Type Default value Description size int or None None scale_factor int or None 2 mode str nearest align_corners bool or None None Please refer to https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html for further detail.","title":"UpSample"},{"location":"modules/#yamlmodule","text":"Argument name Type Default value Description verbose bool False yaml file path and argument configured in yaml module can not be passed through keyword argument.","title":"YamlModule"},{"location":"modules/#pretrained","text":"Argument name Type Default value Description model_name str Please refer to https://rwightman.github.io/pytorch-image-models/results for supported models. ues_feature_maps bool False If True, return value of the module will be list of each feature maps. List[torch.Tensor] (features_only must be True in this case). Otherwise, returns last feature map. features_only bool True If True, skip classification layer and use feature layers only. torch.Tensor pretrained bool True use pretrained weight In case you are just lazy as I am, here is list of pretrained model names. ( timm==0.4.5 ) 'adv_inception_v3', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b2a', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b3a', 'efficientnet_em', 'efficientnet_es', 'efficientnet_lite0', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'gernet_l', 'gernet_m', 'gernet_s', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_rw', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0c', 'pnasnet5large', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet34', 'resnet34d', 'resnet50', 'resnet50d', 'resnet101d', 'resnet152d', 'resnet200d', 'resnetblur50', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_100', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext50_32x4d', 'skresnet18', 'skresnet34', 'skresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tresnet_l', 'tresnet_l_448', 'tresnet_m', 'tresnet_m_448', 'tresnet_xl', 'tresnet_xl_448', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_base_patch16_224', 'vit_base_patch16_224_in21k', 'vit_base_patch16_384', 'vit_base_patch32_224_in21k', 'vit_base_patch32_384', 'vit_base_resnet50_224_in21k', 'vit_base_resnet50_384', 'vit_deit_base_distilled_patch16_224', 'vit_deit_base_distilled_patch16_384', 'vit_deit_base_patch16_224', 'vit_deit_base_patch16_384', 'vit_deit_small_distilled_patch16_224', 'vit_deit_small_patch16_224', 'vit_deit_tiny_distilled_patch16_224', 'vit_deit_tiny_patch16_224', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_small_patch16_224', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception65', 'xception71'","title":"Pretrained"},{"location":"modules/#pretrainedfeaturemap","text":"Argument name Type Default value Description feature_idx int -1 Index of the feature maps","title":"PretrainedFeatureMap"},{"location":"modules/#yolohead","text":"Argument name Type Default value Description n_classes int Number of classes to detect anchors List[List[float]] Anchor lists. Each list represents each layer's anchor and each components in the list represents anchor size of [w1, h1, w2, h2, ...] Note [[-3, -2, -1], 1, YOLOHead, [80, [[100, 200, 200, 100, 200, 200], [50, 100, 100, 50, 100, 100], [10, 20, 20, 10, 20, 20]]]] This represents that YOLOHead takes inputs from previous 3 layers, detects 80 classes with 3 layers of 3 anchors.","title":"YOLOHead"},{"location":"tutorial/","text":"Tutorial 1. Building a PyTorch model with yaml Kindle builds a PyTorch model with yaml file. Components input_size : (Tuple[int, int]) (Optional) Model input image size(height, width). input_channel : (float) Model input channel size. Note ex) If input_size : [32, 32] and input_channel : 3 are given, input size of the model will be (batch_size, 3, 32, 32). When input_size is not provided, Kindle assumes that the model can take any input size. depth_multiple : (float) Depth multiplication factor. width_multiple : (float) Width multiplication factor. channel_divisor : (int) (Optional) (Default: 8) Channel divisor. When width_multiple is adjusted, number of channel is changed to multiple of channel_divisor . Note ex) If width_multiple is 0.5 and the output channel of the module is assigned to 24, the actual output channel is 16 instead of 12 . custom_module_paths : (List[str]) (Optional) Custom module python script path list. backbone : (List[ module ]) Model layers. head : (List[ module ]) (Optional) Model head. This section is same width backbone but width_multiplier is not considered which makes head to have fixed channel size. Note backbone and head consist of module list. module : (List[(int or List[int]), int, str, List]) [ from index , repeat , module name , module arguments ] from index : Index number of the input for the module. -1 represents a previous module. Index number of head is continued from backbone . First module in backbone must have -1 from index value which represents input image. repeat : Repeat number of the module. Ex) When Conv module has repeat: 2 , this module will perform Conv operation twice (Input -> Conv -> Conv). module_name : Name of the module. Pre-built modules are descried here . module_arguments : Arguments of the module. Each module takes pre-defined arguments. Pre-built module arguments are descried here . module_keyword_arguments : Keyword argument of the module. Pre-built module keyword arguments are descried here . Example input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 backbone: [ [-1, 1, Conv, [6, 5, 1, 0], {activation: LeakyReLU}], [-1, 1, MaxPool, [2]], [-1, 1, nn.Conv2d, [16, 5, 1, 2], {bias: False}], [-1, 1, nn.BatchNorm2d, []], [-1, 1, nn.ReLU, []], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], ] head: [ [-1, 1, Linear, [10]] ] Build a model from kindle import Model model = Model ( \"example.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in shape | out shape | ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 616 | Conv | [ 6 , 5 , 1 , 0 ] , activation: LeakyReLU | 3 | 8 | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 3 ,200 | nn.Conv2d | [ 16 , 5 , 1 , 2 ] , bias: False | 8 | 16 | [ 8 16 16 ] | [ 16 , 16 , 16 ] | 3 | -1 | 1 | 32 | nn.BatchNorm2d | [] | 16 | 16 | [ 16 16 16 ] | [ 16 , 16 , 16 ] | 4 | -1 | 1 | 0 | nn.ReLU | [] | 16 | 16 | [ 16 16 16 ] | [ 16 , 16 , 16 ] | 5 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 16 16 ] | [ 16 , 8 , 8 ] | 6 | -1 | 1 | 0 | Flatten | [] | -1 | 1024 | [ 16 8 8 ] | [ 1024 ] | 7 | -1 | 1 | 123 ,000 | Linear | [ 120 , 'ReLU' ] | 1024 | 120 | [ 1024 ] | [ 120 ] | 8 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] | 9 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] | Model Summary: 20 layers, 137 ,862 parameters, 137 ,862 gradients 2. Design Custom Module with YAML You can make your own custom module with yaml file. 1. custom_module.yaml args: [96, 32] module: # [from, repeat, module, args] [ [-1, 1, Conv, [arg0, 1, 1]], [0, 1, Conv, [arg1, 3, 1]], [0, 1, Conv, [arg1, 5, 1]], [0, 1, Conv, [arg1, 7, 1]], [[1, 2, 3], 1, Concat, [1]], [[0, 4], 1, Add, []], ] Arguments of yaml module can be defined as arg0, arg1 ... 2. model_with_custom_module.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 backbone: [ [-1, 1, Conv, [6, 5, 1, 0]], [-1, 1, MaxPool, [2]], [-1, 1, YamlModule, [\"custom_module.yaml\", 48, 16]], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], [-1, 1, Linear, [10]] ] * Note that argument of yaml module can be provided. 3. Build model from kindle import Model model = Model ( \"model_with_custom_module.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in shape | out shape | --------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 616 | Conv | [ 6 , 5 , 1 , 0 ] | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 10 ,832 | YamlModule | [ 'custom_module' ] | [ 8 16 16 ] | [ 24 , 16 , 16 ] | 3 | -1 | 1 | 0 | MaxPool | [ 2 ] | [ 24 16 16 ] | [ 24 , 8 , 8 ] | 4 | -1 | 1 | 0 | Flatten | [] | [ 24 8 8 ] | [ 1536 ] | 5 | -1 | 1 | 184 ,440 | Linear | [ 120 , 'ReLU' ] | [ 1536 ] | [ 120 ] | 6 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | [ 120 ] | [ 84 ] | 7 | -1 | 1 | 850 | Linear | [ 10 ] | [ 84 ] | [ 10 ] | Model Summary: 36 layers, 206 ,902 parameters, 206 ,902 gradients 3. Design Custom Module from Source You can make your own custom module from the source. 1. custom_module_model.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 custom_module_paths: [\"tests.test_custom_module\"] # Paths to the custom modules of the source backbone: # [from, repeat, module, args] [ [-1, 1, MyConv, [6, 5, 3]], [-1, 1, MaxPool, [2]], [-1, 1, MyConv, [16, 3, 5, SiLU]], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], [-1, 1, Linear, [10]] ] 2. Write PyTorch module and ModuleGenerator tests/test_custom_module.py from typing import List , Union , Dict , Any import numpy as np import torch from torch import nn from kindle.generator import GeneratorAbstract from kindle.utils.torch_utils import autopad from kindle.modules.activation import Activation class MyConv ( nn . Module ): def __init__ ( self , in_channels : int , out_channels : int , kernel_size : int , n : int , activation : Union [ str , None ] = \"ReLU\" , ) -> None : super () . __init__ () convs = [] for i in range ( n ): convs . append ( nn . Conv2d ( in_channels , in_channels if ( i + 1 ) != n else out_channels , kernel_size , padding = autopad ( kernel_size ), bias = False , ) ) self . convs = nn . Sequential ( * convs ) self . batch_norm = nn . BatchNorm2d ( out_channels ) self . activation = Activation ( activation )() def forward ( self , x : torch . Tensor ) -> torch . Tensor : return self . activation ( self . batch_norm ( self . convs ( x ))) class MyConvGenerator ( GeneratorAbstract ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) @property def out_channel ( self ) -> int : return self . _get_divisible_channel ( self . args [ 0 ] * self . width_multiply ) @property def in_channel ( self ) -> int : if isinstance ( self . from_idx , list ): raise Exception ( \"from_idx can not be a list.\" ) return self . in_channels [ self . from_idx ] @property def kwargs ( self ) -> Dict [ str , Any ]: args = [ self . in_channel , self . out_channel , * self . args [ 1 :]] return self . _get_kwargs ( MyConv , args ) @torch . no_grad () def compute_out_shape ( self , size : np . ndarray , repeat : int = 1 ) -> List [ int ]: module = self ( repeat = repeat ) module . eval () module_out = module ( torch . zeros ([ 1 , * list ( size )])) return list ( module_out . shape [ - 3 :]) def __call__ ( self , repeat : int = 1 ) -> nn . Module : if repeat > 1 : module = [ MyConv ( ** self . kwargs ) for _ in range ( repeat )] else : module = MyConv ( ** self . kwargs ) return self . _get_module ( module ) 3. Build a model from kindle import Model model = Model ( \"custom_module_model.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in shape | out shape | ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 1 ,066 | MyConv | [ 6 , 5 , 3 ] | 3 | 8 | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 3 ,488 | MyConv | [ 16 , 3 , 5 , 'SiLU' ] | 8 | 16 | [ 8 16 16 ] | [ 16 , 16 , 16 ] | 3 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 16 16 ] | [ 16 , 8 , 8 ] | 4 | -1 | 1 | 0 | Flatten | [] | -1 | 1024 | [ 16 8 8 ] | [ 1024 ] | 5 | -1 | 1 | 123 ,000 | Linear | [ 120 , 'ReLU' ] | 1024 | 120 | [ 1024 ] | [ 120 ] | 6 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] | 7 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] | Model Summary: 29 layers, 138 ,568 parameters, 138 ,568 gradients 4. Utilize pretrained model Pre-trained model from timm can be loaded in kindle yaml config file. Please refer to https://rwightman.github.io/pytorch-image-models/results/ for supported models. Example In this example, we load pretrained efficient-b0 model. Then we extract each feature map layer to apply convolution layer. 1. pretrained_model.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 pretrained: mobilenetv3_small_100 backbone: # [from, repeat, module, args] [ [-1, 1, UpSample, []], [-1, 1, PreTrained, [efficientnet_b0, True]], [1, 1, PreTrainedFeatureMap, [-3]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [-1, 1, MaxPool, [2]], [1, 1, PreTrainedFeatureMap, [-2]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [[-1, -3], 1, Concat, []], [-1, 1, MaxPool, [2]], [1, 1, PreTrainedFeatureMap, [-1]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [[-1, -3], 1, Concat, []], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], ] head: [ [-1, 1, Linear, [10]] ] When PreTrained module has features_only = True argument, the output of the module will be list of each feature map. PreTrainedFeatureMap module simply bypass feature_idx output of PreTrained . 2. Build a model from kindle import Model model = Model ( \"pretrained_model.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in_shape | out_shape -------+----------+-----+-----------+----------------------+-------------------------------+--------------+------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------- 0 | -1 | 1 | 0 | UpSample | [] | 3 | 3 | [ 3 , 32 , 32 ] | [ 3 , 64 , 64 ] 1 | -1 | 1 | 3 ,595,388 | PreTrained | [ 'efficientnet_b0' , True ] | 3 | [ 16 , 24 , 40 , 112 , 320 ] | [ 3 64 64 ] | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] 2 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -3 ] | 40 | 40 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 40 , 8 , 8 ] 3 | -1 | 1 | 336 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 40 | 8 | [ 40 , 8 , 8 ] | [ 8 , 8 , 8 ] 4 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 , 8 , 8 ] | [ 8 , 4 , 4 ] 5 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -2 ] | 112 | 112 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 112 , 4 , 4 ] 6 | -1 | 1 | 912 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 112 | 8 | [ 112 , 4 , 4 ] | [ 8 , 4 , 4 ] 7 | [ -1, -3 ] | 1 | 0 | Concat | [] | -1 | 16 | [ list ([ 8 , 4 , 4 ]) list ([ 8 , 4 , 4 ])] | [ 16 , 4 , 4 ] 8 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 , 4 , 4 ] | [ 16 , 2 , 2 ] 9 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -1 ] | 320 | 320 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 320 , 2 , 2 ] 10 | -1 | 1 | 2 ,576 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 320 | 8 | [ 320 , 2 , 2 ] | [ 8 , 2 , 2 ] 11 | [ -1, -3 ] | 1 | 0 | Concat | [] | -1 | 24 | [ list ([ 8 , 2 , 2 ]) list ([ 16 , 2 , 2 ])] | [ 24 , 2 , 2 ] 12 | -1 | 1 | 0 | Flatten | [] | -1 | 96 | [ 24 , 2 , 2 ] | [ 96 ] 13 | -1 | 1 | 11 ,640 | Linear | [ 120 , 'ReLU' ] | 96 | 120 | [ 96 ] | [ 120 ] 14 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] 15 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] Model Summary: 250 layers, 3 ,621,866 parameters, 3 ,621,866 gradients 5. Make object detectiong model using YOLOHead You can build YOLO with simple configuration. In this example, we made a neck to bypass the feature maps to the YOLOHead but you can build your own detection neck layers. Note In order to compute stride size automatically, you will need to provide arbitrary input_size . However, the model can take any input sizes as the model is allowed to take. 1. yolo_sample.yaml input_size: [256, 256] input_channel: 3 depth_multiple: 0.33 width_multiple: 0.5 anchors: &anchors - [10,13, 16,30, 33,23] # P3/8 - [30,61, 62,45, 59,119] # P4 - [116,90, 156,198, 373,326] # P5/32 n_classes: &n_classes 10 activation: &activation SiLU backbone: # [from, repeat, module, args] [ [-1, 1, Focus, [64, 3], {activation: *activation}], [-1, 1, Conv, [128, 3, 2], {activation: *activation}], [-1, 3, C3, [128], {activation: *activation}], # 2 [-1, 1, Conv, [256, 3, 2], {activation: *activation}], [-1, 9, C3, [256], {activation: *activation}], # 4 [-1, 1, Conv, [512, 3, 2], {activation: *activation}], [-1, 9, C3, [512], {activation: *activation}], # 6 [-1, 1, Conv, [1024, 3, 2], {activation: *activation}], [-1, 1, SPP, [1024, [5, 9, 13]], {activation: *activation}], [-1, 3, C3, [1024, False], {activation: *activation}], # 9 # Neck [-1, 1, Conv, [512, 1, 1], {activation: *activation}], [-1, 1, UpSample, [null, 2]], [[-1, 6], 1, Concat, [1]], [-1, 3, C3, [512, False], {activation: *activation}], # 13 [-1, 1, Conv, [256, 1, 1], {activation: *activation}], [-1, 1, UpSample, [null, 2]], [[-1, 4], 1, Concat, [1]], [-1, 1, C3, [256, False], {activation: *activation}], # 17 [-1, 1, Conv, [256, 3, 2], {activation: *activation}], [[-1, 14], 1, Concat, [1]], [-1, 3, C3, [512, False], {activation: *activation}], # 20 [-1, 1, Conv, [512, 3, 2], {activation: *activation}], [[-1, 10], 1, Concat, [1]], [-1, 3, C3, [1024, False], {activation: *activation}] # 23 ] head: [ [[17, 20, 23], 1, YOLOHead, [*n_classes, *anchors]] ] 2. Build a model from kindle import YOLOModel model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in_shape | out_shape -------+--------------+-----+-----------+----------+--------------------------------------------------------------------------------------------+-----------------+---------------+---------------------------------------+-------------------------------- 0 | -1 | 1 | 3 ,520 | Focus | [ 64 , 3 ] , activation: SiLU | 12 | 32 | [ 3 , 256 , 256 ] | [ 32 , 128 , 128 ] 1 | -1 | 1 | 18 ,560 | Conv | [ 128 , 3 , 2 ] , activation: SiLU | 32 | 64 | [ 32 128 128 ] | [ 64 , 64 , 64 ] 2 | -1 | 1 | 18 ,816 | C3 | [ 128 ] , activation: SiLU | 64 | 64 | [ 64 64 64 ] | [ 64 , 64 , 64 ] 3 | -1 | 1 | 73 ,984 | Conv | [ 256 , 3 , 2 ] , activation: SiLU | 64 | 128 | [ 64 64 64 ] | [ 128 , 32 , 32 ] 4 | -1 | 3 | 156 ,928 | C3 | [ 256 ] , activation: SiLU | 128 | 128 | [ 128 32 32 ] | [ 128 , 32 , 32 ] 5 | -1 | 1 | 295 ,424 | Conv | [ 512 , 3 , 2 ] , activation: SiLU | 128 | 256 | [ 128 32 32 ] | [ 256 , 16 , 16 ] 6 | -1 | 3 | 625 ,152 | C3 | [ 512 ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 16 , 16 ] 7 | -1 | 1 | 1 ,180,672 | Conv | [ 1024 , 3 , 2 ] , activation: SiLU | 256 | 512 | [ 256 16 16 ] | [ 512 , 8 , 8 ] 8 | -1 | 1 | 656 ,896 | SPP | [ 1024 , [ 5 , 9 , 13 ]] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 9 | -1 | 1 | 1 ,182,720 | C3 | [ 1024 , False ] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 10 | -1 | 1 | 131 ,584 | Conv | [ 512 , 1 , 1 ] , activation: SiLU | 512 | 256 | [ 512 8 8 ] | [ 256 , 8 , 8 ] 11 | -1 | 1 | 0 | UpSample | [ None, 2 ] | 256 | 256 | [ 256 8 8 ] | [ 256 , 16 , 16 ] 12 | [ -1, 6 ] | 1 | 0 | Concat | [ 1 ] | -1 | 512 | [[ 256 16 16 ] , [ 256 16 16 ]] | [ 512 , 16 , 16 ] 13 | -1 | 1 | 361 ,984 | C3 | [ 512 , False ] , activation: SiLU | 512 | 256 | [ 512 16 16 ] | [ 256 , 16 , 16 ] 14 | -1 | 1 | 33 ,024 | Conv | [ 256 , 1 , 1 ] , activation: SiLU | 256 | 128 | [ 256 16 16 ] | [ 128 , 16 , 16 ] 15 | -1 | 1 | 0 | UpSample | [ None, 2 ] | 128 | 128 | [ 128 16 16 ] | [ 128 , 32 , 32 ] 16 | [ -1, 4 ] | 1 | 0 | Concat | [ 1 ] | -1 | 256 | [[ 128 32 32 ] , [ 128 32 32 ]] | [ 256 , 32 , 32 ] 17 | -1 | 1 | 90 ,880 | C3 | [ 256 , False ] , activation: SiLU | 256 | 128 | [ 256 32 32 ] | [ 128 , 32 , 32 ] 18 | -1 | 1 | 147 ,712 | Conv | [ 256 , 3 , 2 ] , activation: SiLU | 128 | 128 | [ 128 32 32 ] | [ 128 , 16 , 16 ] 19 | [ -1, 14 ] | 1 | 0 | Concat | [ 1 ] | -1 | 256 | [[ 128 16 16 ] , [ 128 16 16 ]] | [ 256 , 16 , 16 ] 20 | -1 | 1 | 296 ,448 | C3 | [ 512 , False ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 16 , 16 ] 21 | -1 | 1 | 590 ,336 | Conv | [ 512 , 3 , 2 ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 8 , 8 ] 22 | [ -1, 10 ] | 1 | 0 | Concat | [ 1 ] | -1 | 512 | [[ 256 8 8 ] , [ 256 8 8 ]] | [ 512 , 8 , 8 ] 23 | -1 | 1 | 1 ,182,720 | C3 | [ 1024 , False ] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 24 | [ 17 , 20 , 23 ] | 1 | 40 ,455 | YOLOHead | [ 10 , [[ 10 , 13 , 16 , 30 , 33 , 23 ] , [ 30 , 61 , 62 , 45 , 59 , 119 ] , [ 116 , 90 , 156 , 198 , 373 , 326 ]]] | [ 128 , 256 , 512 ] | [ 15 , 15 , 15 ] | [[ 128 32 32 ] , [ 256 16 16 ] , [ 512 8 8 ]] | [[ -1, 15 ] , [ -1, 15 ] , [ -1, 15 ]] Model Summary: 281 layers, 7 ,087,815 parameters, 7 ,087,815 gradients 3. Initialize biases Generally, object detection is better trained when biases is initialized with sample or class distribution. from kindle import YOLOModel # Initialize biases with default. model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True , init_bias = True ) # Initialize biases if classs histogram exists and assume that generally 3 objects are shown up each bounding boxes in 100 images. model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True ) model . initialize_biases ( class_probability = YOUR_CLASS_HISTOGRAM , n_object_per_image = ( 3 , 100 )) # Initialize biases if class histogram does not exists and assuming each class has 60% probability chance to show. model = Model ( \"yolo_sample.yaml\" , verbose = True ) model . initialize_biases ( class_frequency = 0.6 , n_object_per_image = ( 3 , 100 )) Note Initializing bias method is currently experimental and prone to change in near future.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"tutorial/#1-building-a-pytorch-model-with-yaml","text":"Kindle builds a PyTorch model with yaml file.","title":"1. Building a PyTorch model with yaml"},{"location":"tutorial/#components","text":"input_size : (Tuple[int, int]) (Optional) Model input image size(height, width). input_channel : (float) Model input channel size. Note ex) If input_size : [32, 32] and input_channel : 3 are given, input size of the model will be (batch_size, 3, 32, 32). When input_size is not provided, Kindle assumes that the model can take any input size. depth_multiple : (float) Depth multiplication factor. width_multiple : (float) Width multiplication factor. channel_divisor : (int) (Optional) (Default: 8) Channel divisor. When width_multiple is adjusted, number of channel is changed to multiple of channel_divisor . Note ex) If width_multiple is 0.5 and the output channel of the module is assigned to 24, the actual output channel is 16 instead of 12 . custom_module_paths : (List[str]) (Optional) Custom module python script path list. backbone : (List[ module ]) Model layers. head : (List[ module ]) (Optional) Model head. This section is same width backbone but width_multiplier is not considered which makes head to have fixed channel size. Note backbone and head consist of module list. module : (List[(int or List[int]), int, str, List]) [ from index , repeat , module name , module arguments ] from index : Index number of the input for the module. -1 represents a previous module. Index number of head is continued from backbone . First module in backbone must have -1 from index value which represents input image. repeat : Repeat number of the module. Ex) When Conv module has repeat: 2 , this module will perform Conv operation twice (Input -> Conv -> Conv). module_name : Name of the module. Pre-built modules are descried here . module_arguments : Arguments of the module. Each module takes pre-defined arguments. Pre-built module arguments are descried here . module_keyword_arguments : Keyword argument of the module. Pre-built module keyword arguments are descried here .","title":"Components"},{"location":"tutorial/#example","text":"input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 backbone: [ [-1, 1, Conv, [6, 5, 1, 0], {activation: LeakyReLU}], [-1, 1, MaxPool, [2]], [-1, 1, nn.Conv2d, [16, 5, 1, 2], {bias: False}], [-1, 1, nn.BatchNorm2d, []], [-1, 1, nn.ReLU, []], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], ] head: [ [-1, 1, Linear, [10]] ]","title":"Example"},{"location":"tutorial/#build-a-model","text":"from kindle import Model model = Model ( \"example.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in shape | out shape | ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 616 | Conv | [ 6 , 5 , 1 , 0 ] , activation: LeakyReLU | 3 | 8 | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 3 ,200 | nn.Conv2d | [ 16 , 5 , 1 , 2 ] , bias: False | 8 | 16 | [ 8 16 16 ] | [ 16 , 16 , 16 ] | 3 | -1 | 1 | 32 | nn.BatchNorm2d | [] | 16 | 16 | [ 16 16 16 ] | [ 16 , 16 , 16 ] | 4 | -1 | 1 | 0 | nn.ReLU | [] | 16 | 16 | [ 16 16 16 ] | [ 16 , 16 , 16 ] | 5 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 16 16 ] | [ 16 , 8 , 8 ] | 6 | -1 | 1 | 0 | Flatten | [] | -1 | 1024 | [ 16 8 8 ] | [ 1024 ] | 7 | -1 | 1 | 123 ,000 | Linear | [ 120 , 'ReLU' ] | 1024 | 120 | [ 1024 ] | [ 120 ] | 8 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] | 9 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] | Model Summary: 20 layers, 137 ,862 parameters, 137 ,862 gradients","title":"Build a model"},{"location":"tutorial/#2-design-custom-module-with-yaml","text":"You can make your own custom module with yaml file. 1. custom_module.yaml args: [96, 32] module: # [from, repeat, module, args] [ [-1, 1, Conv, [arg0, 1, 1]], [0, 1, Conv, [arg1, 3, 1]], [0, 1, Conv, [arg1, 5, 1]], [0, 1, Conv, [arg1, 7, 1]], [[1, 2, 3], 1, Concat, [1]], [[0, 4], 1, Add, []], ] Arguments of yaml module can be defined as arg0, arg1 ... 2. model_with_custom_module.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 backbone: [ [-1, 1, Conv, [6, 5, 1, 0]], [-1, 1, MaxPool, [2]], [-1, 1, YamlModule, [\"custom_module.yaml\", 48, 16]], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], [-1, 1, Linear, [10]] ] * Note that argument of yaml module can be provided. 3. Build model from kindle import Model model = Model ( \"model_with_custom_module.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in shape | out shape | --------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 616 | Conv | [ 6 , 5 , 1 , 0 ] | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 10 ,832 | YamlModule | [ 'custom_module' ] | [ 8 16 16 ] | [ 24 , 16 , 16 ] | 3 | -1 | 1 | 0 | MaxPool | [ 2 ] | [ 24 16 16 ] | [ 24 , 8 , 8 ] | 4 | -1 | 1 | 0 | Flatten | [] | [ 24 8 8 ] | [ 1536 ] | 5 | -1 | 1 | 184 ,440 | Linear | [ 120 , 'ReLU' ] | [ 1536 ] | [ 120 ] | 6 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | [ 120 ] | [ 84 ] | 7 | -1 | 1 | 850 | Linear | [ 10 ] | [ 84 ] | [ 10 ] | Model Summary: 36 layers, 206 ,902 parameters, 206 ,902 gradients","title":"2. Design Custom Module with YAML"},{"location":"tutorial/#3-design-custom-module-from-source","text":"You can make your own custom module from the source. 1. custom_module_model.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 custom_module_paths: [\"tests.test_custom_module\"] # Paths to the custom modules of the source backbone: # [from, repeat, module, args] [ [-1, 1, MyConv, [6, 5, 3]], [-1, 1, MaxPool, [2]], [-1, 1, MyConv, [16, 3, 5, SiLU]], [-1, 1, MaxPool, [2]], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], [-1, 1, Linear, [10]] ] 2. Write PyTorch module and ModuleGenerator tests/test_custom_module.py from typing import List , Union , Dict , Any import numpy as np import torch from torch import nn from kindle.generator import GeneratorAbstract from kindle.utils.torch_utils import autopad from kindle.modules.activation import Activation class MyConv ( nn . Module ): def __init__ ( self , in_channels : int , out_channels : int , kernel_size : int , n : int , activation : Union [ str , None ] = \"ReLU\" , ) -> None : super () . __init__ () convs = [] for i in range ( n ): convs . append ( nn . Conv2d ( in_channels , in_channels if ( i + 1 ) != n else out_channels , kernel_size , padding = autopad ( kernel_size ), bias = False , ) ) self . convs = nn . Sequential ( * convs ) self . batch_norm = nn . BatchNorm2d ( out_channels ) self . activation = Activation ( activation )() def forward ( self , x : torch . Tensor ) -> torch . Tensor : return self . activation ( self . batch_norm ( self . convs ( x ))) class MyConvGenerator ( GeneratorAbstract ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) @property def out_channel ( self ) -> int : return self . _get_divisible_channel ( self . args [ 0 ] * self . width_multiply ) @property def in_channel ( self ) -> int : if isinstance ( self . from_idx , list ): raise Exception ( \"from_idx can not be a list.\" ) return self . in_channels [ self . from_idx ] @property def kwargs ( self ) -> Dict [ str , Any ]: args = [ self . in_channel , self . out_channel , * self . args [ 1 :]] return self . _get_kwargs ( MyConv , args ) @torch . no_grad () def compute_out_shape ( self , size : np . ndarray , repeat : int = 1 ) -> List [ int ]: module = self ( repeat = repeat ) module . eval () module_out = module ( torch . zeros ([ 1 , * list ( size )])) return list ( module_out . shape [ - 3 :]) def __call__ ( self , repeat : int = 1 ) -> nn . Module : if repeat > 1 : module = [ MyConv ( ** self . kwargs ) for _ in range ( repeat )] else : module = MyConv ( ** self . kwargs ) return self . _get_module ( module ) 3. Build a model from kindle import Model model = Model ( \"custom_module_model.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in shape | out shape | ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0 | -1 | 1 | 1 ,066 | MyConv | [ 6 , 5 , 3 ] | 3 | 8 | [ 3 , 32 , 32 ] | [ 8 , 32 , 32 ] | 1 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 32 32 ] | [ 8 , 16 , 16 ] | 2 | -1 | 1 | 3 ,488 | MyConv | [ 16 , 3 , 5 , 'SiLU' ] | 8 | 16 | [ 8 16 16 ] | [ 16 , 16 , 16 ] | 3 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 16 16 ] | [ 16 , 8 , 8 ] | 4 | -1 | 1 | 0 | Flatten | [] | -1 | 1024 | [ 16 8 8 ] | [ 1024 ] | 5 | -1 | 1 | 123 ,000 | Linear | [ 120 , 'ReLU' ] | 1024 | 120 | [ 1024 ] | [ 120 ] | 6 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] | 7 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] | Model Summary: 29 layers, 138 ,568 parameters, 138 ,568 gradients","title":"3. Design Custom Module from Source"},{"location":"tutorial/#4-utilize-pretrained-model","text":"Pre-trained model from timm can be loaded in kindle yaml config file. Please refer to https://rwightman.github.io/pytorch-image-models/results/ for supported models.","title":"4. Utilize pretrained model"},{"location":"tutorial/#example_1","text":"In this example, we load pretrained efficient-b0 model. Then we extract each feature map layer to apply convolution layer. 1. pretrained_model.yaml input_size: [32, 32] input_channel: 3 depth_multiple: 1.0 width_multiple: 1.0 pretrained: mobilenetv3_small_100 backbone: # [from, repeat, module, args] [ [-1, 1, UpSample, []], [-1, 1, PreTrained, [efficientnet_b0, True]], [1, 1, PreTrainedFeatureMap, [-3]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [-1, 1, MaxPool, [2]], [1, 1, PreTrainedFeatureMap, [-2]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [[-1, -3], 1, Concat, []], [-1, 1, MaxPool, [2]], [1, 1, PreTrainedFeatureMap, [-1]], [-1, 1, Conv, [8, 1], {activation: LeakyReLU}], [[-1, -3], 1, Concat, []], [-1, 1, Flatten, []], [-1, 1, Linear, [120, ReLU]], [-1, 1, Linear, [84, ReLU]], ] head: [ [-1, 1, Linear, [10]] ] When PreTrained module has features_only = True argument, the output of the module will be list of each feature map. PreTrainedFeatureMap module simply bypass feature_idx output of PreTrained . 2. Build a model from kindle import Model model = Model ( \"pretrained_model.yaml\" ), verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in_shape | out_shape -------+----------+-----+-----------+----------------------+-------------------------------+--------------+------------------------+--------------------------------------------------------------------+-------------------------------------------------------------------- 0 | -1 | 1 | 0 | UpSample | [] | 3 | 3 | [ 3 , 32 , 32 ] | [ 3 , 64 , 64 ] 1 | -1 | 1 | 3 ,595,388 | PreTrained | [ 'efficientnet_b0' , True ] | 3 | [ 16 , 24 , 40 , 112 , 320 ] | [ 3 64 64 ] | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] 2 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -3 ] | 40 | 40 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 40 , 8 , 8 ] 3 | -1 | 1 | 336 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 40 | 8 | [ 40 , 8 , 8 ] | [ 8 , 8 , 8 ] 4 | -1 | 1 | 0 | MaxPool | [ 2 ] | 8 | 8 | [ 8 , 8 , 8 ] | [ 8 , 4 , 4 ] 5 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -2 ] | 112 | 112 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 112 , 4 , 4 ] 6 | -1 | 1 | 912 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 112 | 8 | [ 112 , 4 , 4 ] | [ 8 , 4 , 4 ] 7 | [ -1, -3 ] | 1 | 0 | Concat | [] | -1 | 16 | [ list ([ 8 , 4 , 4 ]) list ([ 8 , 4 , 4 ])] | [ 16 , 4 , 4 ] 8 | -1 | 1 | 0 | MaxPool | [ 2 ] | 16 | 16 | [ 16 , 4 , 4 ] | [ 16 , 2 , 2 ] 9 | 1 | 1 | 0 | PreTrainedFeatureMap | [ -1 ] | 320 | 320 | [[ 16 , 32 , 32 ] , [ 24 , 16 , 16 ] , [ 40 , 8 , 8 ] , [ 112 , 4 , 4 ] , [ 320 , 2 , 2 ]] | [ 320 , 2 , 2 ] 10 | -1 | 1 | 2 ,576 | Conv | [ 8 , 1 ] , activation: LeakyReLU | 320 | 8 | [ 320 , 2 , 2 ] | [ 8 , 2 , 2 ] 11 | [ -1, -3 ] | 1 | 0 | Concat | [] | -1 | 24 | [ list ([ 8 , 2 , 2 ]) list ([ 16 , 2 , 2 ])] | [ 24 , 2 , 2 ] 12 | -1 | 1 | 0 | Flatten | [] | -1 | 96 | [ 24 , 2 , 2 ] | [ 96 ] 13 | -1 | 1 | 11 ,640 | Linear | [ 120 , 'ReLU' ] | 96 | 120 | [ 96 ] | [ 120 ] 14 | -1 | 1 | 10 ,164 | Linear | [ 84 , 'ReLU' ] | 120 | 84 | [ 120 ] | [ 84 ] 15 | -1 | 1 | 850 | Linear | [ 10 ] | 84 | 10 | [ 84 ] | [ 10 ] Model Summary: 250 layers, 3 ,621,866 parameters, 3 ,621,866 gradients","title":"Example"},{"location":"tutorial/#5-make-object-detectiong-model-using-yolohead","text":"You can build YOLO with simple configuration. In this example, we made a neck to bypass the feature maps to the YOLOHead but you can build your own detection neck layers. Note In order to compute stride size automatically, you will need to provide arbitrary input_size . However, the model can take any input sizes as the model is allowed to take. 1. yolo_sample.yaml input_size: [256, 256] input_channel: 3 depth_multiple: 0.33 width_multiple: 0.5 anchors: &anchors - [10,13, 16,30, 33,23] # P3/8 - [30,61, 62,45, 59,119] # P4 - [116,90, 156,198, 373,326] # P5/32 n_classes: &n_classes 10 activation: &activation SiLU backbone: # [from, repeat, module, args] [ [-1, 1, Focus, [64, 3], {activation: *activation}], [-1, 1, Conv, [128, 3, 2], {activation: *activation}], [-1, 3, C3, [128], {activation: *activation}], # 2 [-1, 1, Conv, [256, 3, 2], {activation: *activation}], [-1, 9, C3, [256], {activation: *activation}], # 4 [-1, 1, Conv, [512, 3, 2], {activation: *activation}], [-1, 9, C3, [512], {activation: *activation}], # 6 [-1, 1, Conv, [1024, 3, 2], {activation: *activation}], [-1, 1, SPP, [1024, [5, 9, 13]], {activation: *activation}], [-1, 3, C3, [1024, False], {activation: *activation}], # 9 # Neck [-1, 1, Conv, [512, 1, 1], {activation: *activation}], [-1, 1, UpSample, [null, 2]], [[-1, 6], 1, Concat, [1]], [-1, 3, C3, [512, False], {activation: *activation}], # 13 [-1, 1, Conv, [256, 1, 1], {activation: *activation}], [-1, 1, UpSample, [null, 2]], [[-1, 4], 1, Concat, [1]], [-1, 1, C3, [256, False], {activation: *activation}], # 17 [-1, 1, Conv, [256, 3, 2], {activation: *activation}], [[-1, 14], 1, Concat, [1]], [-1, 3, C3, [512, False], {activation: *activation}], # 20 [-1, 1, Conv, [512, 3, 2], {activation: *activation}], [[-1, 10], 1, Concat, [1]], [-1, 3, C3, [1024, False], {activation: *activation}] # 23 ] head: [ [[17, 20, 23], 1, YOLOHead, [*n_classes, *anchors]] ] 2. Build a model from kindle import YOLOModel model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True ) idx | from | n | params | module | arguments | in_channel | out_channel | in_shape | out_shape -------+--------------+-----+-----------+----------+--------------------------------------------------------------------------------------------+-----------------+---------------+---------------------------------------+-------------------------------- 0 | -1 | 1 | 3 ,520 | Focus | [ 64 , 3 ] , activation: SiLU | 12 | 32 | [ 3 , 256 , 256 ] | [ 32 , 128 , 128 ] 1 | -1 | 1 | 18 ,560 | Conv | [ 128 , 3 , 2 ] , activation: SiLU | 32 | 64 | [ 32 128 128 ] | [ 64 , 64 , 64 ] 2 | -1 | 1 | 18 ,816 | C3 | [ 128 ] , activation: SiLU | 64 | 64 | [ 64 64 64 ] | [ 64 , 64 , 64 ] 3 | -1 | 1 | 73 ,984 | Conv | [ 256 , 3 , 2 ] , activation: SiLU | 64 | 128 | [ 64 64 64 ] | [ 128 , 32 , 32 ] 4 | -1 | 3 | 156 ,928 | C3 | [ 256 ] , activation: SiLU | 128 | 128 | [ 128 32 32 ] | [ 128 , 32 , 32 ] 5 | -1 | 1 | 295 ,424 | Conv | [ 512 , 3 , 2 ] , activation: SiLU | 128 | 256 | [ 128 32 32 ] | [ 256 , 16 , 16 ] 6 | -1 | 3 | 625 ,152 | C3 | [ 512 ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 16 , 16 ] 7 | -1 | 1 | 1 ,180,672 | Conv | [ 1024 , 3 , 2 ] , activation: SiLU | 256 | 512 | [ 256 16 16 ] | [ 512 , 8 , 8 ] 8 | -1 | 1 | 656 ,896 | SPP | [ 1024 , [ 5 , 9 , 13 ]] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 9 | -1 | 1 | 1 ,182,720 | C3 | [ 1024 , False ] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 10 | -1 | 1 | 131 ,584 | Conv | [ 512 , 1 , 1 ] , activation: SiLU | 512 | 256 | [ 512 8 8 ] | [ 256 , 8 , 8 ] 11 | -1 | 1 | 0 | UpSample | [ None, 2 ] | 256 | 256 | [ 256 8 8 ] | [ 256 , 16 , 16 ] 12 | [ -1, 6 ] | 1 | 0 | Concat | [ 1 ] | -1 | 512 | [[ 256 16 16 ] , [ 256 16 16 ]] | [ 512 , 16 , 16 ] 13 | -1 | 1 | 361 ,984 | C3 | [ 512 , False ] , activation: SiLU | 512 | 256 | [ 512 16 16 ] | [ 256 , 16 , 16 ] 14 | -1 | 1 | 33 ,024 | Conv | [ 256 , 1 , 1 ] , activation: SiLU | 256 | 128 | [ 256 16 16 ] | [ 128 , 16 , 16 ] 15 | -1 | 1 | 0 | UpSample | [ None, 2 ] | 128 | 128 | [ 128 16 16 ] | [ 128 , 32 , 32 ] 16 | [ -1, 4 ] | 1 | 0 | Concat | [ 1 ] | -1 | 256 | [[ 128 32 32 ] , [ 128 32 32 ]] | [ 256 , 32 , 32 ] 17 | -1 | 1 | 90 ,880 | C3 | [ 256 , False ] , activation: SiLU | 256 | 128 | [ 256 32 32 ] | [ 128 , 32 , 32 ] 18 | -1 | 1 | 147 ,712 | Conv | [ 256 , 3 , 2 ] , activation: SiLU | 128 | 128 | [ 128 32 32 ] | [ 128 , 16 , 16 ] 19 | [ -1, 14 ] | 1 | 0 | Concat | [ 1 ] | -1 | 256 | [[ 128 16 16 ] , [ 128 16 16 ]] | [ 256 , 16 , 16 ] 20 | -1 | 1 | 296 ,448 | C3 | [ 512 , False ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 16 , 16 ] 21 | -1 | 1 | 590 ,336 | Conv | [ 512 , 3 , 2 ] , activation: SiLU | 256 | 256 | [ 256 16 16 ] | [ 256 , 8 , 8 ] 22 | [ -1, 10 ] | 1 | 0 | Concat | [ 1 ] | -1 | 512 | [[ 256 8 8 ] , [ 256 8 8 ]] | [ 512 , 8 , 8 ] 23 | -1 | 1 | 1 ,182,720 | C3 | [ 1024 , False ] , activation: SiLU | 512 | 512 | [ 512 8 8 ] | [ 512 , 8 , 8 ] 24 | [ 17 , 20 , 23 ] | 1 | 40 ,455 | YOLOHead | [ 10 , [[ 10 , 13 , 16 , 30 , 33 , 23 ] , [ 30 , 61 , 62 , 45 , 59 , 119 ] , [ 116 , 90 , 156 , 198 , 373 , 326 ]]] | [ 128 , 256 , 512 ] | [ 15 , 15 , 15 ] | [[ 128 32 32 ] , [ 256 16 16 ] , [ 512 8 8 ]] | [[ -1, 15 ] , [ -1, 15 ] , [ -1, 15 ]] Model Summary: 281 layers, 7 ,087,815 parameters, 7 ,087,815 gradients 3. Initialize biases Generally, object detection is better trained when biases is initialized with sample or class distribution. from kindle import YOLOModel # Initialize biases with default. model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True , init_bias = True ) # Initialize biases if classs histogram exists and assume that generally 3 objects are shown up each bounding boxes in 100 images. model = YOLOModel ( \"yolo_sample.yaml\" , verbose = True ) model . initialize_biases ( class_probability = YOUR_CLASS_HISTOGRAM , n_object_per_image = ( 3 , 100 )) # Initialize biases if class histogram does not exists and assuming each class has 60% probability chance to show. model = Model ( \"yolo_sample.yaml\" , verbose = True ) model . initialize_biases ( class_frequency = 0.6 , n_object_per_image = ( 3 , 100 )) Note Initializing bias method is currently experimental and prone to change in near future.","title":"5. Make object detectiong model using YOLOHead"},{"location":"usages/","text":"Usages AutoML with Optuna Kindle offers the easiest way to build your own deep learning architecture. Beyond building a model, AutoML became easier with Kindle and Optuna or other optimization frameworks. Example code import torch from torch import nn , optim from torchvision import datasets , transforms from torch.utils.data.sampler import SubsetRandomSampler from torch.utils.data import DataLoader from kindle import Model , TorchTrainer import optuna if __name__ == \"__main__\" : device = torch . device ( \"cuda:0\" ) if torch . cuda . is_available () else torch . device ( \"cpu\" ) preprocess = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))] ) train_dataset = datasets . CIFAR10 ( \"./data/cifar10\" , train = True , download = True , transform = preprocess ) test_dataset = datasets . CIFAR10 ( \"./data/cifar10\" , train = False , download = True , transform = preprocess ) subset_sampler = SubsetRandomSampler ( np . arange ( 0 , len ( train_dataset ), 2 )) def objective ( trial : optuna . Trial ): model_cfg = { \"input_size\" : [ 32 , 32 ], \"input_channel\" : 3 , \"depth_multiple\" : 1.0 , \"width_multiple\" : 1.0 } conv_type = trial . suggest_categorical ( \"conv_type\" , [ \"Conv\" , \"DWConv\" ]) kernel_size = trial . suggest_int ( \"kernel_size\" , 3 , 7 , step = 2 ) n_channel_01 = trial . suggest_int ( \"n_channel_01\" , 8 , 64 , step = 8 ) n_channel_02 = trial . suggest_int ( \"n_channel_02\" , 8 , 128 , step = 8 ) linear_activation = trial . suggest_categorical ( \"linear_activation\" , [ \"ReLU\" , \"SiLU\" ]) n_channel_03 = trial . suggest_int ( \"n_channel_03\" , 64 , 256 , step = 8 ) n_channel_04 = trial . suggest_int ( \"n_channel_04\" , 32 , 128 , step = 8 ) n_repeat = trial . suggest_int ( \"n_repeat\" , 1 , 3 ) backbone = [ [ - 1 , n_repeat , conv_type , [ n_channel_01 , kernel_size , 1 ]], [ - 1 , 1 , \"MaxPool\" , [ 2 ]], [ - 1 , n_repeat , conv_type , [ int ( n_channel_02 ), kernel_size , 1 ]], [ - 1 , 1 , \"MaxPool\" , [ 2 ]], [ - 1 , 1 , \"Flatten\" , []], [ - 1 , 1 , \"Linear\" , [ n_channel_03 , linear_activation ]], [ - 1 , 1 , \"Linear\" , [ n_channel_04 , linear_activation ]], [ - 1 , 1 , \"Linear\" , [ 10 ]], ] model_cfg . update ({ \"backbone\" : backbone }) model = Model ( model_cfg , verbose = True ) batch_size = trial . suggest_int ( \"batch_size\" , 8 , 256 ) epochs = trial . suggest_int ( \"epochs\" , 5 , 20 ) train_loader = DataLoader ( train_dataset , batch_size = batch_size , sampler = subset_sampler ) test_loader = DataLoader ( test_dataset , batch_size = batch_size ) criterion = nn . CrossEntropyLoss () optimizer = optim . Adam ( model . parameters ()) trainer = TorchTrainer ( model , criterion , optimizer , device = device ) trainer . train ( train_loader , n_epoch = epochs , test_dataloader = test_loader ) test_loss , test_accuracy = trainer . test ( test_loader ) return test_loss study = optuna . create_study ( study_name = \"Sample AutoML\" , direction = \"minimize\" ) study . optimize ( objective )","title":"Usages"},{"location":"usages/#usages","text":"","title":"Usages"},{"location":"usages/#automl-with-optuna","text":"Kindle offers the easiest way to build your own deep learning architecture. Beyond building a model, AutoML became easier with Kindle and Optuna or other optimization frameworks.","title":"AutoML with Optuna"},{"location":"usages/#example-code","text":"import torch from torch import nn , optim from torchvision import datasets , transforms from torch.utils.data.sampler import SubsetRandomSampler from torch.utils.data import DataLoader from kindle import Model , TorchTrainer import optuna if __name__ == \"__main__\" : device = torch . device ( \"cuda:0\" ) if torch . cuda . is_available () else torch . device ( \"cpu\" ) preprocess = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))] ) train_dataset = datasets . CIFAR10 ( \"./data/cifar10\" , train = True , download = True , transform = preprocess ) test_dataset = datasets . CIFAR10 ( \"./data/cifar10\" , train = False , download = True , transform = preprocess ) subset_sampler = SubsetRandomSampler ( np . arange ( 0 , len ( train_dataset ), 2 )) def objective ( trial : optuna . Trial ): model_cfg = { \"input_size\" : [ 32 , 32 ], \"input_channel\" : 3 , \"depth_multiple\" : 1.0 , \"width_multiple\" : 1.0 } conv_type = trial . suggest_categorical ( \"conv_type\" , [ \"Conv\" , \"DWConv\" ]) kernel_size = trial . suggest_int ( \"kernel_size\" , 3 , 7 , step = 2 ) n_channel_01 = trial . suggest_int ( \"n_channel_01\" , 8 , 64 , step = 8 ) n_channel_02 = trial . suggest_int ( \"n_channel_02\" , 8 , 128 , step = 8 ) linear_activation = trial . suggest_categorical ( \"linear_activation\" , [ \"ReLU\" , \"SiLU\" ]) n_channel_03 = trial . suggest_int ( \"n_channel_03\" , 64 , 256 , step = 8 ) n_channel_04 = trial . suggest_int ( \"n_channel_04\" , 32 , 128 , step = 8 ) n_repeat = trial . suggest_int ( \"n_repeat\" , 1 , 3 ) backbone = [ [ - 1 , n_repeat , conv_type , [ n_channel_01 , kernel_size , 1 ]], [ - 1 , 1 , \"MaxPool\" , [ 2 ]], [ - 1 , n_repeat , conv_type , [ int ( n_channel_02 ), kernel_size , 1 ]], [ - 1 , 1 , \"MaxPool\" , [ 2 ]], [ - 1 , 1 , \"Flatten\" , []], [ - 1 , 1 , \"Linear\" , [ n_channel_03 , linear_activation ]], [ - 1 , 1 , \"Linear\" , [ n_channel_04 , linear_activation ]], [ - 1 , 1 , \"Linear\" , [ 10 ]], ] model_cfg . update ({ \"backbone\" : backbone }) model = Model ( model_cfg , verbose = True ) batch_size = trial . suggest_int ( \"batch_size\" , 8 , 256 ) epochs = trial . suggest_int ( \"epochs\" , 5 , 20 ) train_loader = DataLoader ( train_dataset , batch_size = batch_size , sampler = subset_sampler ) test_loader = DataLoader ( test_dataset , batch_size = batch_size ) criterion = nn . CrossEntropyLoss () optimizer = optim . Adam ( model . parameters ()) trainer = TorchTrainer ( model , criterion , optimizer , device = device ) trainer . train ( train_loader , n_epoch = epochs , test_dataloader = test_loader ) test_loss , test_accuracy = trainer . test ( test_loader ) return test_loss study = optuna . create_study ( study_name = \"Sample AutoML\" , direction = \"minimize\" ) study . optimize ( objective )","title":"Example code"}]}