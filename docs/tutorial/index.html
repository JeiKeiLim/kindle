<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="../img/favicon.ico">
    <title>Tutorial &mdash; Kindle</title>
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/tonsky/FiraCode@1.206/distr/fira_code.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/all.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/v4-shims.css">
    <link rel="stylesheet" href="../css/theme.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    <script src="//code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>
        hljs.initHighlightingOnLoad();
    </script> 
</head>

<body ontouchstart="">
    <div id="container">
        <aside>
            <div class="home">
                <div class="title">
                    <button class="hamburger"></button>
                    <a href=".." class="site-name"> Kindle</a>
                </div>
                <div class="search">
                    <div role="search">
    <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
        <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
    </form>
</div>
                </div>
            </div>
            <nav class="nav">
                <ul class="root">
                    <li class="toctree-l1"><a class="nav-item" href="..">Home</a></li>
                    <li class="toctree-l1"><a class="nav-item" href="../functionality/">Functionality</a></li>
                    <li class="toctree-l1 current"><a class="nav-item current" href="./">Tutorial</a>
<ul class="subnav">
<li class="toctree-l2"><a class="nav-item toc" href="#1-building-a-pytorch-model-with-yaml">1. Building a PyTorch model with yaml</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#2-design-custom-module-with-yaml">2. Design Custom Module with YAML</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#3-design-custom-module-from-source">3. Design Custom Module from Source</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#4-utilize-pretrained-model">4. Utilize pretrained model</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#5-make-object-detectiong-model-using-yolohead">5. Make object detectiong model using YOLOHead</a></li>
</ul></li>
                    <li class="toctree-l1"><a class="nav-item" href="../usages/">Usages</a></li>
                    <li class="toctree-l1"><a class="nav-item" href="../modules/">Modules</a></li>
                </ul>
            </nav>
            <div class="repo">
    <div class="link">
        <a href="https://github.com/JeiKeiLim/kindle/" class="fa fa-github"> GitHub</a>
    </div>
    <div class="previous"><a href="../functionality/">&laquo; Previous</a></div>
    <div class="next"><a href="../usages/">Next &raquo;</a></div>
</div>
        </aside>
        <div id="spacer"><button class="arrow"></button></div>
        <main>
            <div class="home-top">
                <button class="hamburger"></button>
                <a href=".." class="site-name"> Kindle</a>
            </div>
            <div id="main">
                <nav class="breadcrumbs">
<ul>
    
</ul>
</nav>
                <div id="content"><h1 id="tutorial">Tutorial</h1>
<h2 id="1-building-a-pytorch-model-with-yaml">1. Building a PyTorch model with yaml</h2>
<p>Kindle builds a PyTorch model with yaml file.</p>
<h3 id="components">Components</h3>
<ul>
<li><code>input_size</code>: (Tuple[int, int]) (Optional) Model input image size(height, width).</li>
<li>
<p><code>input_channel</code>: (float) Model input channel size.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ex) If <code>input_size</code>: [32, 32] and <code>input_channel</code>: 3 are given, input size of the model will be (batch_size, 3, 32, 32). 
When <code>input_size</code> is not provided, Kindle assumes that the model can take any input size.</p>
</div>
</li>
<li>
<p><code>depth_multiple</code>: (float) Depth multiplication factor.</p>
</li>
<li><code>width_multiple</code>: (float) Width multiplication factor.</li>
<li>
<p><code>channel_divisor</code>: (int) (Optional) (Default: 8) Channel divisor. When <code>width_multiple</code> is adjusted, number of channel is changed to multiple of <code>channel_divisor</code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ex) If <code>width_multiple</code> is 0.5 and the output channel of the module is assigned to 24, the actual output channel is <code>16</code> instead of <code>12</code>.</p>
</div>
</li>
<li>
<p><code>custom_module_paths</code>: (List[str]) (Optional) Custom module python script path list.</p>
</li>
<li>
<p><code>backbone</code>: (List[<code>module</code>]) Model layers. </p>
</li>
<li>
<p><code>head</code>: (List[<code>module</code>]) (Optional) Model head. This section is same width <code>backbone</code> but <code>width_multiplier</code> is not considered which makes <code>head</code> to have fixed channel size.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code>backbone</code> and <code>head</code> consist of <code>module</code> list.</p>
</div>
<ul>
<li>
<p><code>module</code>: (List[(int or List[int]), int, str, List]) [<code>from index</code>, <code>repeat</code>, <code>module name</code>, <code>module arguments</code>]</p>
<ul>
<li>
<p><code>from index</code>: Index number of the input for the module. -1 represents a previous module. 
                Index number of <code>head</code> is continued from <code>backbone</code>.
                First module in <code>backbone</code> must have -1 <code>from index</code> value which represents input image.</p>
</li>
<li>
<p><code>repeat</code>: Repeat number of the module. Ex) When Conv module has <code>repeat: 2</code>, this module will perform Conv operation twice (Input -&gt; Conv -&gt; Conv). </p>
</li>
<li><code>module_name</code>: Name of the module. Pre-built modules are descried <a href="../modules/">here</a>.</li>
<li><code>module_arguments</code>: Arguments of the module. Each module takes pre-defined arguments. Pre-built module arguments are descried <a href="../modules/">here</a>.</li>
<li><code>module_keyword_arguments</code>: Keyword argument of the module. Pre-built module keyword arguments are descried <a href="../modules/">here</a>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="example">Example</h3>
<pre class="highlight"><code>input_size: [32, 32]
input_channel: 3

depth_multiple: 1.0
width_multiple: 1.0

backbone:
    [
        [-1, 1, Conv, [6, 5, 1, 0], {activation: LeakyReLU}],
        [-1, 1, MaxPool, [2]],
        [-1, 1, nn.Conv2d, [16, 5, 1, 2], {bias: False}],
        [-1, 1, nn.BatchNorm2d, []],
        [-1, 1, nn.ReLU, []],
        [-1, 1, MaxPool, [2]],
        [-1, 1, Flatten, []],
        [-1, 1, Linear, [120, ReLU]],
        [-1, 1, Linear, [84, ReLU]],
    ]

head:
  [
        [-1, 1, Linear, [10]]
  ]</code></pre>
<h3 id="build-a-model">Build a model</h3>
<pre class="highlight"><code class="language-python">from kindle import Model

model = Model("example.yaml"), verbose=True)</code></pre>
<pre class="highlight"><code class="language-shell">idx |       from |   n |   params |          module |                           arguments | in_channel | out_channel |        in shape |       out shape |
----------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |         -1 |   1 |      616 |            Conv | [6, 5, 1, 0], activation: LeakyReLU |          3 |           8 |     [3, 32, 32] |     [8, 32, 32] |
  1 |         -1 |   1 |        0 |         MaxPool |                                 [2] |          8 |           8 |       [8 32 32] |     [8, 16, 16] |
  2 |         -1 |   1 |    3,200 |       nn.Conv2d |          [16, 5, 1, 2], bias: False |          8 |          16 |       [8 16 16] |    [16, 16, 16] |
  3 |         -1 |   1 |       32 |  nn.BatchNorm2d |                                  [] |         16 |          16 |      [16 16 16] |    [16, 16, 16] |
  4 |         -1 |   1 |        0 |         nn.ReLU |                                  [] |         16 |          16 |      [16 16 16] |    [16, 16, 16] |
  5 |         -1 |   1 |        0 |         MaxPool |                                 [2] |         16 |          16 |      [16 16 16] |      [16, 8, 8] |
  6 |         -1 |   1 |        0 |         Flatten |                                  [] |         -1 |        1024 |        [16 8 8] |          [1024] |
  7 |         -1 |   1 |  123,000 |          Linear |                       [120, 'ReLU'] |       1024 |         120 |          [1024] |           [120] |
  8 |         -1 |   1 |   10,164 |          Linear |                        [84, 'ReLU'] |        120 |          84 |           [120] |            [84] |
  9 |         -1 |   1 |      850 |          Linear |                                [10] |         84 |          10 |            [84] |            [10] |
Model Summary: 20 layers, 137,862 parameters, 137,862 gradients</code></pre>
<h2 id="2-design-custom-module-with-yaml">2. Design Custom Module with YAML</h2>
<p>You can make your own custom module with yaml file.</p>
<p><strong>1. custom_module.yaml</strong>
<pre class="highlight"><code>args: [96, 32]

module:
    # [from, repeat, module, args]
    [
        [-1, 1, Conv, [arg0, 1, 1]],
        [0, 1, Conv, [arg1, 3, 1]],
        [0, 1, Conv, [arg1, 5, 1]],
        [0, 1, Conv, [arg1, 7, 1]],
        [[1, 2, 3], 1, Concat, [1]],
        [[0, 4], 1, Add, []],
    ]</code></pre></p>
<ul>
<li>Arguments of yaml module can be defined as arg0, arg1 ...</li>
</ul>
<p><strong>2. model_with_custom_module.yaml</strong>
<pre class="highlight"><code>input_size: [32, 32]
input_channel: 3

depth_multiple: 1.0
width_multiple: 1.0

backbone:
    [
        [-1, 1, Conv, [6, 5, 1, 0]],
        [-1, 1, MaxPool, [2]],
        [-1, 1, YamlModule, ["custom_module.yaml", 48, 16]],
        [-1, 1, MaxPool, [2]],
        [-1, 1, Flatten, []],
        [-1, 1, Linear, [120, ReLU]],
        [-1, 1, Linear, [84, ReLU]],
        [-1, 1, Linear, [10]]
    ]</code></pre>
* Note that argument of yaml module can be provided.</p>
<p><strong>3. Build model</strong>
<pre class="highlight"><code class="language-python">from kindle import Model

model = Model("model_with_custom_module.yaml"), verbose=True)</code></pre>
<pre class="highlight"><code class="language-shell">idx |       from |   n |     params |          module |            arguments |                       in shape |       out shape |
---------------------------------------------------------------------------------------------------------------------------------
  0 |         -1 |   1 |        616 |            Conv |         [6, 5, 1, 0] |                    [3, 32, 32] |     [8, 32, 32] |
  1 |         -1 |   1 |          0 |         MaxPool |                  [2] |                      [8 32 32] |     [8, 16, 16] |
  2 |         -1 |   1 |     10,832 |      YamlModule |    ['custom_module'] |                      [8 16 16] |    [24, 16, 16] |
  3 |         -1 |   1 |          0 |         MaxPool |                  [2] |                     [24 16 16] |      [24, 8, 8] |
  4 |         -1 |   1 |          0 |         Flatten |                   [] |                       [24 8 8] |          [1536] |
  5 |         -1 |   1 |    184,440 |          Linear |        [120, 'ReLU'] |                         [1536] |           [120] |
  6 |         -1 |   1 |     10,164 |          Linear |         [84, 'ReLU'] |                          [120] |            [84] |
  7 |         -1 |   1 |        850 |          Linear |                 [10] |                           [84] |            [10] |
Model Summary: 36 layers, 206,902 parameters, 206,902 gradients</code></pre></p>
<h2 id="3-design-custom-module-from-source">3. Design Custom Module from Source</h2>
<p>You can make your own custom module from the source.</p>
<p><strong>1. custom_module_model.yaml</strong>
<pre class="highlight"><code>input_size: [32, 32]
input_channel: 3

depth_multiple: 1.0
width_multiple: 1.0

custom_module_paths: ["tests.test_custom_module"]  # Paths to the custom modules of the source

backbone:
    # [from, repeat, module, args]
    [
        [-1, 1, MyConv, [6, 5, 3]],
        [-1, 1, MaxPool, [2]],
        [-1, 1, MyConv, [16, 3, 5, SiLU]],
        [-1, 1, MaxPool, [2]],
        [-1, 1, Flatten, []],
        [-1, 1, Linear, [120, ReLU]],
        [-1, 1, Linear, [84, ReLU]],
        [-1, 1, Linear, [10]]
    ]</code></pre></p>
<p><strong>2. Write</strong> <strong><em>PyTorch</em></strong> <strong>module and</strong> <strong><em>ModuleGenerator</em></strong></p>
<p>tests/test_custom_module.py</p>
<pre class="highlight"><code class="language-python">from typing import List, Union, Dict, Any

import numpy as np
import torch
from torch import nn

from kindle.generator import GeneratorAbstract
from kindle.utils.torch_utils import autopad
from kindle.modules.activation import Activation


class MyConv(nn.Module):
    def __init__(
            self,
            in_channels: int,
            out_channels: int,
            kernel_size: int,
            n: int,
            activation: Union[str, None] = "ReLU",
    ) -&gt; None:
        super().__init__()
        convs = []
        for i in range(n):
            convs.append(
                nn.Conv2d(
                    in_channels,
                    in_channels if (i + 1) != n else out_channels,
                    kernel_size,
                    padding=autopad(kernel_size),
                    bias=False,
                )
            )

        self.convs = nn.Sequential(*convs)
        self.batch_norm = nn.BatchNorm2d(out_channels)
        self.activation = Activation(activation)()

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        return self.activation(self.batch_norm(self.convs(x)))


class MyConvGenerator(GeneratorAbstract):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    def out_channel(self) -&gt; int:
        return self._get_divisible_channel(self.args[0] * self.width_multiply)

    @property
    def in_channel(self) -&gt; int:
        if isinstance(self.from_idx, list):
            raise Exception("from_idx can not be a list.")
        return self.in_channels[self.from_idx]

    @property
    def kwargs(self) -&gt; Dict[str, Any]:
        args = [self.in_channel, self.out_channel, *self.args[1:]]
        return self._get_kwargs(MyConv, args)

    @torch.no_grad()
    def compute_out_shape(self, size: np.ndarray, repeat: int = 1) -&gt; List[int]:
        module = self(repeat=repeat)
        module.eval()
        module_out = module(torch.zeros([1, *list(size)]))
        return list(module_out.shape[-3:])

    def __call__(self, repeat: int = 1) -&gt; nn.Module:
        if repeat &gt; 1:
            module = [MyConv(**self.kwargs) for _ in range(repeat)]
        else:
            module = MyConv(**self.kwargs)

        return self._get_module(module)</code></pre>
<p><strong>3. Build a model</strong>
<pre class="highlight"><code class="language-python">from kindle import Model

model = Model("custom_module_model.yaml"), verbose=True)</code></pre>
<pre class="highlight"><code class="language-shell">idx |       from |   n |   params |          module |                           arguments | in_channel | out_channel |        in shape |       out shape |
----------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |         -1 |   1 |    1,066 |          MyConv |                           [6, 5, 3] |          3 |           8 |     [3, 32, 32] |     [8, 32, 32] |
  1 |         -1 |   1 |        0 |         MaxPool |                                 [2] |          8 |           8 |       [8 32 32] |     [8, 16, 16] |
  2 |         -1 |   1 |    3,488 |          MyConv |                  [16, 3, 5, 'SiLU'] |          8 |          16 |       [8 16 16] |    [16, 16, 16] |
  3 |         -1 |   1 |        0 |         MaxPool |                                 [2] |         16 |          16 |      [16 16 16] |      [16, 8, 8] |
  4 |         -1 |   1 |        0 |         Flatten |                                  [] |         -1 |        1024 |        [16 8 8] |          [1024] |
  5 |         -1 |   1 |  123,000 |          Linear |                       [120, 'ReLU'] |       1024 |         120 |          [1024] |           [120] |
  6 |         -1 |   1 |   10,164 |          Linear |                        [84, 'ReLU'] |        120 |          84 |           [120] |            [84] |
  7 |         -1 |   1 |      850 |          Linear |                                [10] |         84 |          10 |            [84] |            [10] |
Model Summary: 29 layers, 138,568 parameters, 138,568 gradients</code></pre></p>
<h2 id="4-utilize-pretrained-model">4. Utilize pretrained model</h2>
<p>Pre-trained model from <a href="https://github.com/rwightman/pytorch-image-models">timm</a> can be loaded in kindle yaml config file.
Please refer to <a href="https://rwightman.github.io/pytorch-image-models/results/">https://rwightman.github.io/pytorch-image-models/results/</a> for supported models.</p>
<h3 id="example_1">Example</h3>
<ul>
<li>In this example, we load pretrained efficient-b0 model. Then we extract each feature map layer to apply convolution layer.  </li>
</ul>
<p><strong>1. pretrained_model.yaml</strong>
<pre class="highlight"><code>input_size: [32, 32]
input_channel: 3

depth_multiple: 1.0
width_multiple: 1.0

pretrained: mobilenetv3_small_100

backbone:
    # [from, repeat, module, args]
    [
        [-1, 1, UpSample, []],
        [-1, 1, PreTrained, [efficientnet_b0, True]],
        [1, 1, PreTrainedFeatureMap, [-3]],
        [-1, 1, Conv, [8, 1], {activation: LeakyReLU}],
        [-1, 1, MaxPool, [2]],

        [1, 1, PreTrainedFeatureMap, [-2]],
        [-1, 1, Conv, [8, 1], {activation: LeakyReLU}],
        [[-1, -3], 1, Concat, []],
        [-1, 1, MaxPool, [2]],

        [1, 1, PreTrainedFeatureMap, [-1]],
        [-1, 1, Conv, [8, 1], {activation: LeakyReLU}],
        [[-1, -3], 1, Concat, []],

        [-1, 1, Flatten, []],
        [-1, 1, Linear, [120, ReLU]],
        [-1, 1, Linear, [84, ReLU]],
    ]

head:
  [
    [-1, 1, Linear, [10]]
  ]</code></pre></p>
<ul>
<li>When <code>PreTrained</code> module has <code>features_only = True</code> argument, the output of the module will be list of each feature map.</li>
<li><code>PreTrainedFeatureMap</code> module simply bypass <code>feature_idx</code> output of <code>PreTrained</code>. </li>
</ul>
<p><strong>2. Build a model</strong>
<pre class="highlight"><code class="language-python">from kindle import Model

model = Model("pretrained_model.yaml"), verbose=True)</code></pre></p>
<pre class="highlight"><code class="language-shell">   idx | from     |   n | params    | module               | arguments                     |   in_channel | out_channel            | in_shape                                                           | out_shape
-------+----------+-----+-----------+----------------------+-------------------------------+--------------+------------------------+--------------------------------------------------------------------+--------------------------------------------------------------------
     0 | -1       |   1 | 0         | UpSample             | []                            |            3 | 3                      | [3, 32, 32]                                                        | [3, 64, 64]
     1 | -1       |   1 | 3,595,388 | PreTrained           | ['efficientnet_b0', True]     |            3 | [16, 24, 40, 112, 320] | [3 64 64]                                                          | [[16, 32, 32], [24, 16, 16], [40, 8, 8], [112, 4, 4], [320, 2, 2]]
     2 | 1        |   1 | 0         | PreTrainedFeatureMap | [-3]                          |           40 | 40                     | [[16, 32, 32], [24, 16, 16], [40, 8, 8], [112, 4, 4], [320, 2, 2]] | [40, 8, 8]
     3 | -1       |   1 | 336       | Conv                 | [8, 1], activation: LeakyReLU |           40 | 8                      | [40, 8, 8]                                                         | [8, 8, 8]
     4 | -1       |   1 | 0         | MaxPool              | [2]                           |            8 | 8                      | [8, 8, 8]                                                          | [8, 4, 4]
     5 | 1        |   1 | 0         | PreTrainedFeatureMap | [-2]                          |          112 | 112                    | [[16, 32, 32], [24, 16, 16], [40, 8, 8], [112, 4, 4], [320, 2, 2]] | [112, 4, 4]
     6 | -1       |   1 | 912       | Conv                 | [8, 1], activation: LeakyReLU |          112 | 8                      | [112, 4, 4]                                                        | [8, 4, 4]
     7 | [-1, -3] |   1 | 0         | Concat               | []                            |           -1 | 16                     | [list([8, 4, 4]) list([8, 4, 4])]                                  | [16, 4, 4]
     8 | -1       |   1 | 0         | MaxPool              | [2]                           |           16 | 16                     | [16, 4, 4]                                                         | [16, 2, 2]
     9 | 1        |   1 | 0         | PreTrainedFeatureMap | [-1]                          |          320 | 320                    | [[16, 32, 32], [24, 16, 16], [40, 8, 8], [112, 4, 4], [320, 2, 2]] | [320, 2, 2]
    10 | -1       |   1 | 2,576     | Conv                 | [8, 1], activation: LeakyReLU |          320 | 8                      | [320, 2, 2]                                                        | [8, 2, 2]
    11 | [-1, -3] |   1 | 0         | Concat               | []                            |           -1 | 24                     | [list([8, 2, 2]) list([16, 2, 2])]                                 | [24, 2, 2]
    12 | -1       |   1 | 0         | Flatten              | []                            |           -1 | 96                     | [24, 2, 2]                                                         | [96]
    13 | -1       |   1 | 11,640    | Linear               | [120, 'ReLU']                 |           96 | 120                    | [96]                                                               | [120]
    14 | -1       |   1 | 10,164    | Linear               | [84, 'ReLU']                  |          120 | 84                     | [120]                                                              | [84]
    15 | -1       |   1 | 850       | Linear               | [10]                          |           84 | 10                     | [84]                                                               | [10]
Model Summary: 250 layers, 3,621,866 parameters, 3,621,866 gradients</code></pre>
<h2 id="5-make-object-detectiong-model-using-yolohead">5. Make object detectiong model using YOLOHead</h2>
<ul>
<li>You can build YOLO with simple configuration.</li>
<li>In this example, we made a neck to bypass the feature maps to the YOLOHead but you can build your own detection neck layers.</li>
</ul>
<div class="admonition note input_size">
<p class="admonition-title">Note</p>
<p>In order to compute stride size automatically, you will need to provide arbitrary <code>input_size</code>.
However, the model can take any input sizes as the model is allowed to take.</p>
</div>
<p><strong>1. yolo_sample.yaml</strong>
<pre class="highlight"><code>input_size: [256, 256]
input_channel: 3

depth_multiple: 0.33
width_multiple: 0.5

anchors: &amp;anchors
   - [10,13, 16,30, 33,23]  # P3/8
   - [30,61, 62,45, 59,119]  # P4
   - [116,90, 156,198, 373,326]  # P5/32

n_classes: &amp;n_classes
  10

backbone:
    # [from, repeat, module, args]
    [
        [-1, 1, Focus, [64, 3]],
        [-1, 1, Conv, [128, 3, 2]],
        [-1, 3, BottleneckCSP, [128]],  # 2

        [-1, 1, Conv, [256, 3, 2]],
        [-1, 9, BottleneckCSP, [256]],  # 4

        [-1, 1, Conv, [512, 3, 2]],
        [-1, 9, BottleneckCSP, [512]],  # 6

        [-1, 1, Conv, [1024, 3, 2]],
        [-1, 1, SPP, [1024, [5, 9, 13]]],
        [-1, 3, BottleneckCSP, [1024, False]],  # 9

        [-1, 1, Conv, [512, 1, 1]],
        [-1, 1, UpSample, [null, 2]],
        [[-1, 6], 1, Concat, [1]],
        [-1, 3, BottleneckCSP, [512, False]],  # 13

        [-1, 1, Conv, [256, 1, 1]],
        [-1, 1, UpSample, [null, 2]],
        [[-1, 4], 1, Concat, [1]],
        [-1, 1, BottleneckCSP, [256, False]],  # 17

        [-1, 1, Conv, [256, 3, 2]],
        [[-1, 14], 1, Concat, [1]],
        [-1, 3, BottleneckCSP, [512, False]],  # 20

        [-1, 1, Conv, [512, 3, 2]],
        [[-1, 10], 1, Concat, [1]],
        [-1, 3, BottleneckCSP, [1024, False]]  # 23
    ]

head:
  [
    [[17, 20, 23], 1, YOLOHead, [*n_classes, *anchors]]
  ]</code></pre></p>
<p><strong>2. Build a model</strong>
<pre class="highlight"><code class="language-python">from kindle import YOLOModel

model = YOLOModel("yolo_sample.yaml", verbose=True)</code></pre></p>
<pre class="highlight"><code class="language-shell">   idx | from         |   n | params    | module        | arguments                                                                                  | in_channel      | out_channel   | in_shape                              | out_shape
-------+--------------+-----+-----------+---------------+--------------------------------------------------------------------------------------------+-----------------+---------------+---------------------------------------+--------------------------------
     0 | -1           |   1 | 3,520     | Focus         | [64, 3]                                                                                    | 12              | 32            | [3, 256, 256]                         | [32, 128, 128]
     1 | -1           |   1 | 18,560    | Conv          | [128, 3, 2]                                                                                | 32              | 64            | [32 128 128]                          | [64, 64, 64]
     2 | -1           |   1 | 19,904    | BottleneckCSP | [128]                                                                                      | 64              | 64            | [64 64 64]                            | [64, 64, 64]
     3 | -1           |   1 | 73,984    | Conv          | [256, 3, 2]                                                                                | 64              | 128           | [64 64 64]                            | [128, 32, 32]
     4 | -1           |   3 | 161,152   | BottleneckCSP | [256]                                                                                      | 128             | 128           | [128 32 32]                           | [128, 32, 32]
     5 | -1           |   1 | 295,424   | Conv          | [512, 3, 2]                                                                                | 128             | 256           | [128 32 32]                           | [256, 16, 16]
     6 | -1           |   3 | 641,792   | BottleneckCSP | [512]                                                                                      | 256             | 256           | [256 16 16]                           | [256, 16, 16]
     7 | -1           |   1 | 1,180,672 | Conv          | [1024, 3, 2]                                                                               | 256             | 512           | [256 16 16]                           | [512, 8, 8]
     8 | -1           |   1 | 656,896   | SPP           | [1024, [5, 9, 13]]                                                                         | 512             | 512           | [512 8 8]                             | [512, 8, 8]
     9 | -1           |   1 | 1,248,768 | BottleneckCSP | [1024, False]                                                                              | 512             | 512           | [512 8 8]                             | [512, 8, 8]
    10 | -1           |   1 | 131,584   | Conv          | [512, 1, 1]                                                                                | 512             | 256           | [512 8 8]                             | [256, 8, 8]
    11 | -1           |   1 | 0         | UpSample      | [None, 2]                                                                                  | 256             | 256           | [256 8 8]                             | [256, 16, 16]
    12 | [-1, 6]      |   1 | 0         | Concat        | [1]                                                                                        | -1              | 512           | [[256 16 16], [256 16 16]]            | [512, 16, 16]
    13 | -1           |   1 | 378,624   | BottleneckCSP | [512, False]                                                                               | 512             | 256           | [512 16 16]                           | [256, 16, 16]
    14 | -1           |   1 | 33,024    | Conv          | [256, 1, 1]                                                                                | 256             | 128           | [256 16 16]                           | [128, 16, 16]
    15 | -1           |   1 | 0         | UpSample      | [None, 2]                                                                                  | 128             | 128           | [128 16 16]                           | [128, 32, 32]
    16 | [-1, 4]      |   1 | 0         | Concat        | [1]                                                                                        | -1              | 256           | [[128 32 32], [128 32 32]]            | [256, 32, 32]
    17 | -1           |   1 | 95,104    | BottleneckCSP | [256, False]                                                                               | 256             | 128           | [256 32 32]                           | [128, 32, 32]
    18 | -1           |   1 | 147,712   | Conv          | [256, 3, 2]                                                                                | 128             | 128           | [128 32 32]                           | [128, 16, 16]
    19 | [-1, 14]     |   1 | 0         | Concat        | [1]                                                                                        | -1              | 256           | [[128 16 16], [128 16 16]]            | [256, 16, 16]
    20 | -1           |   1 | 313,088   | BottleneckCSP | [512, False]                                                                               | 256             | 256           | [256 16 16]                           | [256, 16, 16]
    21 | -1           |   1 | 590,336   | Conv          | [512, 3, 2]                                                                                | 256             | 256           | [256 16 16]                           | [256, 8, 8]
    22 | [-1, 10]     |   1 | 0         | Concat        | [1]                                                                                        | -1              | 512           | [[256 8 8], [256 8 8]]                | [512, 8, 8]
    23 | -1           |   1 | 1,248,768 | BottleneckCSP | [1024, False]                                                                              | 512             | 512           | [512 8 8]                             | [512, 8, 8]
    24 | [17, 20, 23] |   1 | 40,455    | YOLOHead      | [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]] | [128, 256, 512] | [15, 15, 15]  | [[128 32 32], [256 16 16], [512 8 8]] | [[-1, 15], [-1, 15], [-1, 15]]
Model Summary: 281 layers, 7,279,367 parameters, 7,279,367 gradients</code></pre>
<p><strong>3. Initialize biases</strong></p>
<ul>
<li>Generally, object detection is better trained when biases is initialized with sample or class distribution.</li>
</ul>
<pre class="highlight"><code class="language-python">from kindle import YOLOModel

# Initialize biases if classs histogram exists and assume that generally 3 objects are shown up each bounding boxes in 100 images.
model = YOLOModel("yolo_sample.yaml", verbose=True)
model.initialize_biases(class_probability=YOUR_CLASS_HISTOGRAM, n_object_per_image=(3, 100))

# Initialize biases if class histogram does not exists and assuming each class has 60% probability chance to show.
model = Model("yolo_sample.yaml", verbose=True)
model.initialize_biases(class_frequency=0.6, n_object_per_image=(3, 100))</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Initializing bias method is currently experimental and prone to change in near future.</p>
</div></div>
                <footer>
    <div class="footer-buttons">
        <div class="previous"><a href="../functionality/" title="Functionality"><span>Previous</span></a></div>
        <div class="next"><a href="../usages/" title="Usages"><span>Next</span></a></div>
    </div>
    <div class="footer-note">
        <p>
            Built with <a href="http://www.mkdocs.org">MkDocs</a> using
            <a href="https://github.com/daizutabi/mkdocs-ivory">Ivory theme</a>.
        </p>
    </div>
</footer>
            </div>
        </main>
    </div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
    <script src="../search/main.js"></script>
</body>

</html>